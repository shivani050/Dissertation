{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zjPukxy6_gCd",
        "outputId": "5bcb698d-16ef-45fa-ea6b-6577fffca298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.2.2\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp311-cp311-linux_x86_64.whl (757.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.3/757.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.17.2\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.17.2%2Bcu121-cp311-cp311-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.2.2\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.2.0 (from torch==2.2.2)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.2) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.2) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.2) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2+cu121 torchaudio-2.2.2+cu121 torchvision-0.17.2+cu121 triton-2.2.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_scatter-2.1.2%2Bpt22cu121-cp311-cp311-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt22cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_sparse-0.6.18%2Bpt22cu121-cp311-cp311-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.16.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt22cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu121.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_cluster-1.6.3%2Bpt22cu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.16.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt22cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Collecting tree_sitter\n",
            "  Downloading tree_sitter-0.25.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading tree_sitter-0.25.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (632 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.4/632.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tree_sitter\n",
            "Successfully installed tree_sitter-0.25.0\n"
          ]
        }
      ],
      "source": [
        "# Base torch install with GPU (Colab's default CUDA is 11.8 or 12.1)\n",
        "!pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# PyG dependencies with CUDA 12.1\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.0+cu121.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.2.0+cu121.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.2.0+cu121.html\n",
        "!pip install torch-geometric\n",
        "\n",
        "# Supporting libraries\n",
        "!pip install tree_sitter networkx pandas tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iwgF4yRLAN5_",
        "outputId": "b9729348-63c0-4fb2-a170-afd09bcc4e84"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/devign_project/devign_tokens.csv')\n",
        "print(df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "Oo4K_cH1AtV7",
        "outputId": "73218122-6eb7-4ad2-eed2-86f79cb0b844"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27318, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                               code  \\\n",
              "0   0  static av_cold int vdadec_init(AVCodecContext ...   \n",
              "1   1  static int transcode(AVFormatContext **output_...   \n",
              "2   2  static void v4l2_free_buffer(void *opaque, uin...   \n",
              "3   3  int ff_get_wav_header(AVFormatContext *s, AVIO...   \n",
              "4   4  int av_opencl_buffer_write(cl_mem dst_cl_buf, ...   \n",
              "\n",
              "                                           input_ids  \\\n",
              "0  [0, 42653, 6402, 1215, 33912, 6979, 748, 417, ...   \n",
              "1  [0, 42653, 6979, 6214, 20414, 1640, 10612, 485...   \n",
              "2  [0, 42653, 13842, 748, 306, 462, 176, 1215, 37...   \n",
              "3  [0, 2544, 48400, 1215, 6460, 1215, 48479, 1215...   \n",
              "4  [0, 2544, 6402, 1215, 12592, 3998, 1215, 47438...   \n",
              "\n",
              "                                      attention_mask  label  \n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28200a93-0c42-4186-bf4b-4dd2be8040f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>code</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>static av_cold int vdadec_init(AVCodecContext ...</td>\n",
              "      <td>[0, 42653, 6402, 1215, 33912, 6979, 748, 417, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>static int transcode(AVFormatContext **output_...</td>\n",
              "      <td>[0, 42653, 6979, 6214, 20414, 1640, 10612, 485...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>static void v4l2_free_buffer(void *opaque, uin...</td>\n",
              "      <td>[0, 42653, 13842, 748, 306, 462, 176, 1215, 37...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>int ff_get_wav_header(AVFormatContext *s, AVIO...</td>\n",
              "      <td>[0, 2544, 48400, 1215, 6460, 1215, 48479, 1215...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>int av_opencl_buffer_write(cl_mem dst_cl_buf, ...</td>\n",
              "      <td>[0, 2544, 6402, 1215, 12592, 3998, 1215, 47438...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28200a93-0c42-4186-bf4b-4dd2be8040f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28200a93-0c42-4186-bf4b-4dd2be8040f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28200a93-0c42-4186-bf4b-4dd2be8040f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3952e0ec-3001-4310-b5d0-76ba4364d5d1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3952e0ec-3001-4310-b5d0-76ba4364d5d1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3952e0ec-3001-4310-b5d0-76ba4364d5d1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 27318,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7886,\n        \"min\": 0,\n        \"max\": 27317,\n        \"num_unique_values\": 27318,\n        \"samples\": [\n          11264,\n          20121,\n          22477\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27258,\n        \"samples\": [\n          \"static int img_resize(int argc, char **argv)\\n\\n{\\n\\n    int c, ret, relative;\\n\\n    const char *filename, *fmt, *size;\\n\\n    int64_t n, total_size;\\n\\n    BlockDriverState *bs = NULL;\\n\\n    QemuOpts *param;\\n\\n    static QemuOptsList resize_options = {\\n\\n        .name = \\\"resize_options\\\",\\n\\n        .head = QTAILQ_HEAD_INITIALIZER(resize_options.head),\\n\\n        .desc = {\\n\\n            {\\n\\n                .name = BLOCK_OPT_SIZE,\\n\\n                .type = QEMU_OPT_SIZE,\\n\\n                .help = \\\"Virtual disk size\\\"\\n\\n            }, {\\n\\n                /* end of list */\\n\\n            }\\n\\n        },\\n\\n    };\\n\\n\\n\\n    /* Remove size from argv manually so that negative numbers are not treated\\n\\n     * as options by getopt. */\\n\\n    if (argc < 3) {\\n\\n        help();\\n\\n        return 1;\\n\\n    }\\n\\n\\n\\n    size = argv[--argc];\\n\\n\\n\\n    /* Parse getopt arguments */\\n\\n    fmt = NULL;\\n\\n    for(;;) {\\n\\n        c = getopt(argc, argv, \\\"f:h\\\");\\n\\n        if (c == -1) {\\n\\n            break;\\n\\n        }\\n\\n        switch(c) {\\n\\n        case '?':\\n\\n        case 'h':\\n\\n            help();\\n\\n            break;\\n\\n        case 'f':\\n\\n            fmt = optarg;\\n\\n            break;\\n\\n        }\\n\\n    }\\n\\n    if (optind >= argc) {\\n\\n        help();\\n\\n    }\\n\\n    filename = argv[optind++];\\n\\n\\n\\n    /* Choose grow, shrink, or absolute resize mode */\\n\\n    switch (size[0]) {\\n\\n    case '+':\\n\\n        relative = 1;\\n\\n        size++;\\n\\n        break;\\n\\n    case '-':\\n\\n        relative = -1;\\n\\n        size++;\\n\\n        break;\\n\\n    default:\\n\\n        relative = 0;\\n\\n        break;\\n\\n    }\\n\\n\\n\\n    /* Parse size */\\n\\n    param = qemu_opts_create(&resize_options, NULL, 0, NULL);\\n\\n    if (qemu_opt_set(param, BLOCK_OPT_SIZE, size)) {\\n\\n        /* Error message already printed when size parsing fails */\\n\\n        ret = -1;\\n\\n        qemu_opts_del(param);\\n\\n        goto out;\\n\\n    }\\n\\n    n = qemu_opt_get_size(param, BLOCK_OPT_SIZE, 0);\\n\\n    qemu_opts_del(param);\\n\\n\\n\\n    bs = bdrv_new_open(filename, fmt, BDRV_O_FLAGS | BDRV_O_RDWR);\\n\\n    if (!bs) {\\n\\n        ret = -1;\\n\\n        goto out;\\n\\n    }\\n\\n\\n\\n    if (relative) {\\n\\n        total_size = bdrv_getlength(bs) + n * relative;\\n\\n    } else {\\n\\n        total_size = n;\\n\\n    }\\n\\n    if (total_size <= 0) {\\n\\n        error_report(\\\"New image size must be positive\\\");\\n\\n        ret = -1;\\n\\n        goto out;\\n\\n    }\\n\\n\\n\\n    ret = bdrv_truncate(bs, total_size);\\n\\n    switch (ret) {\\n\\n    case 0:\\n\\n        printf(\\\"Image resized.\\\\n\\\");\\n\\n        break;\\n\\n    case -ENOTSUP:\\n\\n        error_report(\\\"This image does not support resize\\\");\\n\\n        break;\\n\\n    case -EACCES:\\n\\n        error_report(\\\"Image is read-only\\\");\\n\\n        break;\\n\\n    default:\\n\\n        error_report(\\\"Error resizing image (%d)\\\", -ret);\\n\\n        break;\\n\\n    }\\n\\nout:\\n\\n    if (bs) {\\n\\n        bdrv_delete(bs);\\n\\n    }\\n\\n    if (ret) {\\n\\n        return 1;\\n\\n    }\\n\\n    return 0;\\n\\n}\\n\",\n          \"static void tcg_handle_interrupt(CPUArchState *env, int mask)\\n\\n{\\n\\n    CPUState *cpu = ENV_GET_CPU(env);\\n\\n    int old_mask;\\n\\n\\n\\n    old_mask = env->interrupt_request;\\n\\n    env->interrupt_request |= mask;\\n\\n\\n\\n    /*\\n\\n     * If called from iothread context, wake the target cpu in\\n\\n     * case its halted.\\n\\n     */\\n\\n    if (!qemu_cpu_is_self(cpu)) {\\n\\n        qemu_cpu_kick(cpu);\\n\\n        return;\\n\\n    }\\n\\n\\n\\n    if (use_icount) {\\n\\n        env->icount_decr.u16.high = 0xffff;\\n\\n        if (!can_do_io(env)\\n\\n            && (mask & ~old_mask) != 0) {\\n\\n            cpu_abort(env, \\\"Raised interrupt while not in I/O function\\\");\\n\\n        }\\n\\n    } else {\\n\\n        cpu_unlink_tb(cpu);\\n\\n    }\\n\\n}\\n\",\n          \"static int vqf_probe(AVProbeData *probe_packet)\\n{\\n    if (AV_RL32(probe_packet->buf) != MKTAG('T','W','I','N'))\\n        return 0;\\n    if (!memcmp(probe_packet->buf + 4, \\\"97012000\\\", 8))\\n        return AVPROBE_SCORE_MAX;\\n    if (!memcmp(probe_packet->buf + 4, \\\"00052200\\\", 8))\\n        return AVPROBE_SCORE_MAX;\\n    return AVPROBE_SCORE_EXTENSION;\\n}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26500,\n        \"samples\": [\n          \"[0, 42653, 6979, 43756, 1215, 24846, 1215, 10806, 1640, 10612, 48587, 48522, 1009, 1469, 49575, 6, 17307, 36757, 1009, 620, 6, 10759, 16224, 1009, 13650, 6, 6979, 1836, 43, 50118, 50118, 45152, 50140, 1437, 1437, 1437, 17307, 6454, 48522, 1009, 45306, 5457, 6402, 49575, 46613, 45306, 131, 50140, 1437, 1437, 1437, 114, 48209, 6031, 48427, 1640, 13650, 6, 22, 30529, 47992, 1215, 347, 34494, 49293, 25522, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1690, 46613, 40460, 1215, 42786, 5457, 15747, 1215, 12745, 1215, 2544, 1640, 45306, 6, 1836, 4397, 50140, 1437, 1437, 1437, 35524, 1493, 114, 48209, 6031, 48427, 1640, 13650, 6, 22, 44741, 6454, 1215, 38036, 2571, 49293, 25522, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1690, 46613, 29659, 3204, 46613, 29659, 3204, 1215, 808, 5457, 15747, 1215, 12745, 1215, 2544, 1640, 45306, 6, 1836, 4397, 50140, 1437, 1437, 1437, 35524, 1493, 114, 48209, 6031, 48427, 1640, 13650, 6, 22, 10370, 27177, 7744, 49293, 25522, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1690, 46613, 29659, 3204, 46613, 29659, 3204, 1215, 10058, 5457, 15747, 1215, 12745, 1215, 2544, 1640, 45306, 6, 1836, 4397, 50140, 1437, 1437, 1437, 35524, 1493, 114, 48209, 6031, 48427, 1640, 13650, 6, 22, 10089, 47697, 1215, 43302, 49293, 25522, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 15747, 1215, 12745, 1215, 43702, 1640, 1469, 49575, 6, 766, 6, 1836, 4397, 50140, 1437, 1437, 1437, 35524, 1493, 114, 48209, 6031, 48427, 1640, 13650, 6, 22, 46758, 1215, 3764, 15118, 16416, 49293, 25522, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 2]\",\n          \"[0, 2544, 6402, 1535, 29069, 1215, 6460, 1215, 9244, 15072, 1640, 10612, 45646, 20028, 29069, 48522, 1009, 1469, 338, 6, 1457, 1009, 9244, 15072, 6, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 6979, 22265, 43, 50118, 50118, 45152, 50140, 1437, 1437, 1437, 6979, 11, 1215, 611, 34735, 6, 66, 1215, 611, 34735, 6, 939, 6, 1021, 131, 50140, 50140, 1437, 1437, 1437, 11, 1215, 611, 34735, 1437, 5457, 6402, 1215, 6460, 1215, 27681, 1215, 48842, 1215, 40460, 1215, 611, 34735, 1640, 1469, 338, 46613, 179, 1215, 27681, 1215, 48842, 4397, 50140, 1437, 1437, 1437, 66, 1215, 611, 34735, 5457, 6402, 1215, 6460, 1215, 27681, 1215, 48842, 1215, 40460, 1215, 611, 34735, 1640, 1469, 338, 46613, 995, 1215, 27681, 1215, 48842, 4397, 50140, 50140, 1437, 1437, 1437, 114, 36, 11, 1215, 611, 34735, 28696, 321, 45056, 1437, 11, 1215, 611, 34735, 8061, 83, 13055, 1723, 2620, 26050, 1215, 30187, 1215, 3764, 15118, 16416, 45056, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 66, 1215, 611, 34735, 28696, 321, 45056, 66, 1215, 611, 34735, 8061, 83, 13055, 1723, 2620, 26050, 1215, 30187, 1215, 3764, 15118, 16416, 43, 25522, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 6402, 1215, 12376, 1640, 1469, 338, 6, 17307, 1215, 45403, 1215, 46734, 6, 22, 49695, 4238, 41993, 37457, 282, 45751, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 83, 9847, 45055, 1640, 717, 2444, 39766, 4397, 50140, 1437, 1437, 1437, 35524, 2]\",\n          \"[0, 42653, 6979, 16935, 642, 1215, 37785, 1215, 41483, 1640, 597, 15993, 48522, 1009, 29, 6, 10759, 16224, 1009, 41483, 6, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 10759, 6979, 1263, 1215, 43892, 10975, 7479, 16224, 13540, 41510, 43, 50118, 50118, 45152, 50140, 1437, 1437, 1437, 6979, 22379, 131, 50140, 50140, 1437, 1437, 1437, 48565, 4150, 3810, 797, 2748, 8135, 7, 120, 7495, 9, 786, 4249, 8823, 114, 143, 48404, 50140, 1437, 1437, 1437, 114, 41006, 14385, 5457, 16935, 642, 1215, 47742, 1215, 17665, 1215, 46797, 1640, 29, 35122, 28696, 321, 43, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 22379, 131, 50140, 50140, 1437, 1437, 1437, 48565, 2142, 5936, 11, 8890, 5745, 48404, 50140, 1437, 1437, 1437, 579, 46613, 22854, 1215, 17665, 1215, 16776, 1215, 30160, 5457, 321, 131, 50140, 1437, 1437, 1437, 114, 41006, 14385, 5457, 48400, 6423, 1215, 29631, 1640, 29, 46613, 22854, 1215, 17665, 6, 5936, 6, 7031, 8476, 1640, 41483, 47619, 28696, 321, 43, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 22379, 131, 50140, 1437, 1437, 1437, 114, 48209, 14385, 43, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 111, 134, 131, 50140, 50140, 1437, 1437, 1437, 48565, 671, 2194, 48404, 50140, 1437, 1437, 1437, 114, 36, 41510, 1215, 43892, 43, 25522, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 671, 16935, 642, 1215, 29552, 1640, 29, 6, 1263, 6, 1263, 1215, 43892, 4397, 50140, 2]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attention_mask\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 242,\n        \"samples\": [\n          \"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\",\n          \"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\",\n          \"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tree_sitter import Language\n",
        "\n",
        "Language.build_library(\n",
        "    'build/my-languages.so',\n",
        "    ['tree-sitter-c']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "t99YSDvwBFo6",
        "outputId": "9f94d79d-3fb7-4aab-c5a6-c118af49c0b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tree_sitter/__init__.py:36: FutureWarning: Language.build_library is deprecated. Use the new bindings instead.\n",
            "  warn(\"{} is deprecated. Use {} instead.\".format(old, new), FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ed9906a1",
        "outputId": "edf5c862-cb2b-45eb-c9dd-f4595cd30cb1"
      },
      "source": [
        "!pip uninstall tree_sitter -y\n",
        "!rm -rf tree-sitter-c build/\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tree-sitter 0.21.0\n",
            "Uninstalling tree-sitter-0.21.0:\n",
            "  Successfully uninstalled tree-sitter-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinstall tree_sitter (matching grammar version 14)\n",
        "!pip install tree_sitter==0.20.4\n",
        "\n",
        "# Redownload compatible C grammar (older commit)\n",
        "!git clone https://github.com/tree-sitter/tree-sitter-c\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1idvAeaiDhOH",
        "outputId": "76f53291-e2c5-49ef-b665-dac5e76f3b31"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tree_sitter==0.20.4\n",
            "  Downloading tree_sitter-0.20.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Downloading tree_sitter-0.20.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (490 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.5/490.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tree_sitter\n",
            "Successfully installed tree_sitter-0.20.4\n",
            "Cloning into 'tree-sitter-c'...\n",
            "remote: Enumerating objects: 2912, done.\u001b[K\n",
            "remote: Counting objects: 100% (994/994), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 2912 (delta 906), reused 838 (delta 838), pack-reused 1918 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2912/2912), 17.70 MiB | 9.87 MiB/s, done.\n",
            "Resolving deltas: 100% (1829/1829), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd tree-sitter-c\n",
        "!git checkout 8f76d5f623b13d40d81b8e8fc29437523f3846de\n",
        "%cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "L8g-fzNFDiJi",
        "outputId": "c0398114-7a4b-41bd-b220-db2827b1ed71"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tree-sitter-c\n",
            "fatal: reference is not a tree: 8f76d5f623b13d40d81b8e8fc29437523f3846de\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tree_sitter import Language\n",
        "\n",
        "Language.build_library(\n",
        "    'build/my-languages.so',\n",
        "    ['tree-sitter-c']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AAdnXNbEDwSX",
        "outputId": "d162c8da-7ef9-400e-844a-790044e24331"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tree_sitter/__init__.py:36: FutureWarning: Language.build_library is deprecated. Use the new bindings instead.\n",
            "  warn(\"{} is deprecated. Use {} instead.\".format(old, new), FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install pycparser and networkx (if not already installed in the Colab environment)\n",
        "!pip install pycparser networkx --quiet\n"
      ],
      "metadata": {
        "id": "h7r8Vb_eL-5l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-install after Colab runtime reset\n",
        "!pip install pycparser networkx --quiet\n"
      ],
      "metadata": {
        "id": "AJDPPpZaMAMi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Upload the Devign CSV\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "vGFuZ8KyMF7e",
        "outputId": "ccde705c-49ae-4fa8-f064-a469dca3953c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a6dea86f-f39e-43b9-9515-e9840ca4c4d8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a6dea86f-f39e-43b9-9515-e9840ca4c4d8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving devign_tokens.csv to devign_tokens.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load and inspect the data\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"devign_tokens.csv\")\n",
        "# Include 'input_ids' in the selected columns\n",
        "df = df[['id', 'code', 'input_ids', 'label']]\n",
        "display(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yp0yyEAaMjLP",
        "outputId": "fadbdc85-dea1-4120-9013-513d89cc5500"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   id                                               code  \\\n",
              "0   0  static av_cold int vdadec_init(AVCodecContext ...   \n",
              "1   1  static int transcode(AVFormatContext **output_...   \n",
              "2   2  static void v4l2_free_buffer(void *opaque, uin...   \n",
              "3   3  int ff_get_wav_header(AVFormatContext *s, AVIO...   \n",
              "4   4  int av_opencl_buffer_write(cl_mem dst_cl_buf, ...   \n",
              "\n",
              "                                           input_ids  label  \n",
              "0  [0, 42653, 6402, 1215, 33912, 6979, 748, 417, ...      0  \n",
              "1  [0, 42653, 6979, 6214, 20414, 1640, 10612, 485...      0  \n",
              "2  [0, 42653, 13842, 748, 306, 462, 176, 1215, 37...      0  \n",
              "3  [0, 2544, 48400, 1215, 6460, 1215, 48479, 1215...      0  \n",
              "4  [0, 2544, 6402, 1215, 12592, 3998, 1215, 47438...      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a13bb95-6b95-45a7-a1fd-e2de0fb500c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>code</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>static av_cold int vdadec_init(AVCodecContext ...</td>\n",
              "      <td>[0, 42653, 6402, 1215, 33912, 6979, 748, 417, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>static int transcode(AVFormatContext **output_...</td>\n",
              "      <td>[0, 42653, 6979, 6214, 20414, 1640, 10612, 485...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>static void v4l2_free_buffer(void *opaque, uin...</td>\n",
              "      <td>[0, 42653, 13842, 748, 306, 462, 176, 1215, 37...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>int ff_get_wav_header(AVFormatContext *s, AVIO...</td>\n",
              "      <td>[0, 2544, 48400, 1215, 6460, 1215, 48479, 1215...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>int av_opencl_buffer_write(cl_mem dst_cl_buf, ...</td>\n",
              "      <td>[0, 2544, 6402, 1215, 12592, 3998, 1215, 47438...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a13bb95-6b95-45a7-a1fd-e2de0fb500c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a13bb95-6b95-45a7-a1fd-e2de0fb500c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a13bb95-6b95-45a7-a1fd-e2de0fb500c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f417e046-09d9-4b21-9826-6f5f9936bcd7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f417e046-09d9-4b21-9826-6f5f9936bcd7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f417e046-09d9-4b21-9826-6f5f9936bcd7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"static int transcode(AVFormatContext **output_files,\\n\\n                     int nb_output_files,\\n\\n                     InputFile *input_files,\\n\\n                     int nb_input_files,\\n\\n                     StreamMap *stream_maps, int nb_stream_maps)\\n\\n{\\n\\n    int ret = 0, i, j, k, n, nb_ostreams = 0, step;\\n\\n\\n\\n    AVFormatContext *is, *os;\\n\\n    AVCodecContext *codec, *icodec;\\n\\n    OutputStream *ost, **ost_table = NULL;\\n\\n    InputStream *ist;\\n\\n    char error[1024];\\n\\n    int key;\\n\\n    int want_sdp = 1;\\n\\n    uint8_t no_packet[MAX_FILES]={0};\\n\\n    int no_packet_count=0;\\n\\n    int nb_frame_threshold[AVMEDIA_TYPE_NB]={0};\\n\\n    int nb_streams[AVMEDIA_TYPE_NB]={0};\\n\\n\\n\\n    if (rate_emu)\\n\\n        for (i = 0; i < nb_input_streams; i++)\\n\\n            input_streams[i].start = av_gettime();\\n\\n\\n\\n    /* output stream init */\\n\\n    nb_ostreams = 0;\\n\\n    for(i=0;i<nb_output_files;i++) {\\n\\n        os = output_files[i];\\n\\n        if (!os->nb_streams && !(os->oformat->flags & AVFMT_NOSTREAMS)) {\\n\\n            av_dump_format(output_files[i], i, output_files[i]->filename, 1);\\n\\n            fprintf(stderr, \\\"Output file #%d does not contain any stream\\\\n\\\", i);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto fail;\\n\\n        }\\n\\n        nb_ostreams += os->nb_streams;\\n\\n    }\\n\\n    if (nb_stream_maps > 0 && nb_stream_maps != nb_ostreams) {\\n\\n        fprintf(stderr, \\\"Number of stream maps must match number of output streams\\\\n\\\");\\n\\n        ret = AVERROR(EINVAL);\\n\\n        goto fail;\\n\\n    }\\n\\n\\n\\n    /* Sanity check the mapping args -- do the input files & streams exist? */\\n\\n    for(i=0;i<nb_stream_maps;i++) {\\n\\n        int fi = stream_maps[i].file_index;\\n\\n        int si = stream_maps[i].stream_index;\\n\\n\\n\\n        if (fi < 0 || fi > nb_input_files - 1 ||\\n\\n            si < 0 || si > input_files[fi].ctx->nb_streams - 1) {\\n\\n            fprintf(stderr,\\\"Could not find input stream #%d.%d\\\\n\\\", fi, si);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto fail;\\n\\n        }\\n\\n        fi = stream_maps[i].sync_file_index;\\n\\n        si = stream_maps[i].sync_stream_index;\\n\\n        if (fi < 0 || fi > nb_input_files - 1 ||\\n\\n            si < 0 || si > input_files[fi].ctx->nb_streams - 1) {\\n\\n            fprintf(stderr,\\\"Could not find sync stream #%d.%d\\\\n\\\", fi, si);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto fail;\\n\\n        }\\n\\n    }\\n\\n\\n\\n    ost_table = av_mallocz(sizeof(OutputStream *) * nb_ostreams);\\n\\n    if (!ost_table)\\n\\n        goto fail;\\n\\n\\n\\n    for(k=0;k<nb_output_files;k++) {\\n\\n        os = output_files[k];\\n\\n        for(i=0;i<os->nb_streams;i++,n++) {\\n\\n            nb_streams[os->streams[i]->codec->codec_type]++;\\n\\n        }\\n\\n    }\\n\\n    for(step=1<<30; step; step>>=1){\\n\\n        int found_streams[AVMEDIA_TYPE_NB]={0};\\n\\n        for(j=0; j<AVMEDIA_TYPE_NB; j++)\\n\\n            nb_frame_threshold[j] += step;\\n\\n\\n\\n        for(j=0; j<nb_input_streams; j++) {\\n\\n            int skip=0;\\n\\n            ist = &input_streams[j];\\n\\n            if(opt_programid){\\n\\n                int pi,si;\\n\\n                AVFormatContext *f= input_files[ ist->file_index ].ctx;\\n\\n                skip=1;\\n\\n                for(pi=0; pi<f->nb_programs; pi++){\\n\\n                    AVProgram *p= f->programs[pi];\\n\\n                    if(p->id == opt_programid)\\n\\n                        for(si=0; si<p->nb_stream_indexes; si++){\\n\\n                            if(f->streams[ p->stream_index[si] ] == ist->st)\\n\\n                                skip=0;\\n\\n                        }\\n\\n                }\\n\\n            }\\n\\n            if (ist->discard && ist->st->discard != AVDISCARD_ALL && !skip\\n\\n                && nb_frame_threshold[ist->st->codec->codec_type] <= ist->st->codec_info_nb_frames){\\n\\n                found_streams[ist->st->codec->codec_type]++;\\n\\n            }\\n\\n        }\\n\\n        for(j=0; j<AVMEDIA_TYPE_NB; j++)\\n\\n            if(found_streams[j] < nb_streams[j])\\n\\n                nb_frame_threshold[j] -= step;\\n\\n    }\\n\\n    n = 0;\\n\\n    for(k=0;k<nb_output_files;k++) {\\n\\n        os = output_files[k];\\n\\n        for(i=0;i<os->nb_streams;i++,n++) {\\n\\n            int found;\\n\\n            ost = ost_table[n] = output_streams_for_file[k][i];\\n\\n            if (nb_stream_maps > 0) {\\n\\n                ost->source_index = input_files[stream_maps[n].file_index].ist_index +\\n\\n                    stream_maps[n].stream_index;\\n\\n\\n\\n                /* Sanity check that the stream types match */\\n\\n                if (input_streams[ost->source_index].st->codec->codec_type != ost->st->codec->codec_type) {\\n\\n                    int i= ost->file_index;\\n\\n                    av_dump_format(output_files[i], i, output_files[i]->filename, 1);\\n\\n                    fprintf(stderr, \\\"Codec type mismatch for mapping #%d.%d -> #%d.%d\\\\n\\\",\\n\\n                        stream_maps[n].file_index, stream_maps[n].stream_index,\\n\\n                        ost->file_index, ost->index);\\n\\n                    ffmpeg_exit(1);\\n\\n                }\\n\\n\\n\\n            } else {\\n\\n                /* get corresponding input stream index : we select the first one with the right type */\\n\\n                found = 0;\\n\\n                for (j = 0; j < nb_input_streams; j++) {\\n\\n                    int skip=0;\\n\\n                    ist = &input_streams[j];\\n\\n                    if(opt_programid){\\n\\n                        int pi,si;\\n\\n                        AVFormatContext *f = input_files[ist->file_index].ctx;\\n\\n                        skip=1;\\n\\n                        for(pi=0; pi<f->nb_programs; pi++){\\n\\n                            AVProgram *p= f->programs[pi];\\n\\n                            if(p->id == opt_programid)\\n\\n                                for(si=0; si<p->nb_stream_indexes; si++){\\n\\n                                    if(f->streams[ p->stream_index[si] ] == ist->st)\\n\\n                                        skip=0;\\n\\n                                }\\n\\n                        }\\n\\n                    }\\n\\n                    if (ist->discard && ist->st->discard != AVDISCARD_ALL && !skip &&\\n\\n                        ist->st->codec->codec_type == ost->st->codec->codec_type &&\\n\\n                        nb_frame_threshold[ist->st->codec->codec_type] <= ist->st->codec_info_nb_frames) {\\n\\n                            ost->source_index = j;\\n\\n                            found = 1;\\n\\n                            break;\\n\\n                    }\\n\\n                }\\n\\n\\n\\n                if (!found) {\\n\\n                    if(! opt_programid) {\\n\\n                        /* try again and reuse existing stream */\\n\\n                        for (j = 0; j < nb_input_streams; j++) {\\n\\n                            ist = &input_streams[j];\\n\\n                            if (   ist->st->codec->codec_type == ost->st->codec->codec_type\\n\\n                                && ist->st->discard != AVDISCARD_ALL) {\\n\\n                                ost->source_index = j;\\n\\n                                found = 1;\\n\\n                            }\\n\\n                        }\\n\\n                    }\\n\\n                    if (!found) {\\n\\n                        int i= ost->file_index;\\n\\n                        av_dump_format(output_files[i], i, output_files[i]->filename, 1);\\n\\n                        fprintf(stderr, \\\"Could not find input stream matching output stream #%d.%d\\\\n\\\",\\n\\n                                ost->file_index, ost->index);\\n\\n                        ffmpeg_exit(1);\\n\\n                    }\\n\\n                }\\n\\n            }\\n\\n            ist = &input_streams[ost->source_index];\\n\\n            ist->discard = 0;\\n\\n            ost->sync_ist = (nb_stream_maps > 0) ?\\n\\n                &input_streams[input_files[stream_maps[n].sync_file_index].ist_index +\\n\\n                         stream_maps[n].sync_stream_index] : ist;\\n\\n        }\\n\\n    }\\n\\n\\n\\n    /* for each output stream, we compute the right encoding parameters */\\n\\n    for(i=0;i<nb_ostreams;i++) {\\n\\n        ost = ost_table[i];\\n\\n        os = output_files[ost->file_index];\\n\\n        ist = &input_streams[ost->source_index];\\n\\n\\n\\n        codec = ost->st->codec;\\n\\n        icodec = ist->st->codec;\\n\\n\\n\\n        if (metadata_streams_autocopy)\\n\\n            av_dict_copy(&ost->st->metadata, ist->st->metadata,\\n\\n                         AV_DICT_DONT_OVERWRITE);\\n\\n\\n\\n        ost->st->disposition = ist->st->disposition;\\n\\n        codec->bits_per_raw_sample= icodec->bits_per_raw_sample;\\n\\n        codec->chroma_sample_location = icodec->chroma_sample_location;\\n\\n\\n\\n        if (ost->st->stream_copy) {\\n\\n            uint64_t extra_size = (uint64_t)icodec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE;\\n\\n\\n\\n            if (extra_size > INT_MAX)\\n\\n                goto fail;\\n\\n\\n\\n            /* if stream_copy is selected, no need to decode or encode */\\n\\n            codec->codec_id = icodec->codec_id;\\n\\n            codec->codec_type = icodec->codec_type;\\n\\n\\n\\n            if(!codec->codec_tag){\\n\\n                if(   !os->oformat->codec_tag\\n\\n                   || av_codec_get_id (os->oformat->codec_tag, icodec->codec_tag) == codec->codec_id\\n\\n                   || av_codec_get_tag(os->oformat->codec_tag, icodec->codec_id) <= 0)\\n\\n                    codec->codec_tag = icodec->codec_tag;\\n\\n            }\\n\\n\\n\\n            codec->bit_rate = icodec->bit_rate;\\n\\n            codec->rc_max_rate    = icodec->rc_max_rate;\\n\\n            codec->rc_buffer_size = icodec->rc_buffer_size;\\n\\n            codec->extradata= av_mallocz(extra_size);\\n\\n            if (!codec->extradata)\\n\\n                goto fail;\\n\\n            memcpy(codec->extradata, icodec->extradata, icodec->extradata_size);\\n\\n            codec->extradata_size= icodec->extradata_size;\\n\\n            if(!copy_tb && av_q2d(icodec->time_base)*icodec->ticks_per_frame > av_q2d(ist->st->time_base) && av_q2d(ist->st->time_base) < 1.0/500){\\n\\n                codec->time_base = icodec->time_base;\\n\\n                codec->time_base.num *= icodec->ticks_per_frame;\\n\\n                av_reduce(&codec->time_base.num, &codec->time_base.den,\\n\\n                          codec->time_base.num, codec->time_base.den, INT_MAX);\\n\\n            }else\\n\\n                codec->time_base = ist->st->time_base;\\n\\n            switch(codec->codec_type) {\\n\\n            case AVMEDIA_TYPE_AUDIO:\\n\\n                if(audio_volume != 256) {\\n\\n                    fprintf(stderr,\\\"-acodec copy and -vol are incompatible (frames are not decoded)\\\\n\\\");\\n\\n                    ffmpeg_exit(1);\\n\\n                }\\n\\n                codec->channel_layout = icodec->channel_layout;\\n\\n                codec->sample_rate = icodec->sample_rate;\\n\\n                codec->channels = icodec->channels;\\n\\n                codec->frame_size = icodec->frame_size;\\n\\n                codec->audio_service_type = icodec->audio_service_type;\\n\\n                codec->block_align= icodec->block_align;\\n\\n                if(codec->block_align == 1 && codec->codec_id == CODEC_ID_MP3)\\n\\n                    codec->block_align= 0;\\n\\n                if(codec->codec_id == CODEC_ID_AC3)\\n\\n                    codec->block_align= 0;\\n\\n                break;\\n\\n            case AVMEDIA_TYPE_VIDEO:\\n\\n                codec->pix_fmt = icodec->pix_fmt;\\n\\n                codec->width = icodec->width;\\n\\n                codec->height = icodec->height;\\n\\n                codec->has_b_frames = icodec->has_b_frames;\\n\\n                if (!codec->sample_aspect_ratio.num) {\\n\\n                    codec->sample_aspect_ratio =\\n\\n                    ost->st->sample_aspect_ratio =\\n\\n                        ist->st->sample_aspect_ratio.num ? ist->st->sample_aspect_ratio :\\n\\n                        ist->st->codec->sample_aspect_ratio.num ?\\n\\n                        ist->st->codec->sample_aspect_ratio : (AVRational){0, 1};\\n\\n                }\\n\\n                break;\\n\\n            case AVMEDIA_TYPE_SUBTITLE:\\n\\n                codec->width = icodec->width;\\n\\n                codec->height = icodec->height;\\n\\n                break;\\n\\n            case AVMEDIA_TYPE_DATA:\\n\\n                break;\\n\\n            default:\\n\\n                abort();\\n\\n            }\\n\\n        } else {\\n\\n            if (!ost->enc)\\n\\n                ost->enc = avcodec_find_encoder(ost->st->codec->codec_id);\\n\\n            switch(codec->codec_type) {\\n\\n            case AVMEDIA_TYPE_AUDIO:\\n\\n                ost->fifo= av_fifo_alloc(1024);\\n\\n                if(!ost->fifo)\\n\\n                    goto fail;\\n\\n                ost->reformat_pair = MAKE_SFMT_PAIR(AV_SAMPLE_FMT_NONE,AV_SAMPLE_FMT_NONE);\\n\\n                if (!codec->sample_rate) {\\n\\n                    codec->sample_rate = icodec->sample_rate;\\n\\n                    if (icodec->lowres)\\n\\n                        codec->sample_rate >>= icodec->lowres;\\n\\n                }\\n\\n                choose_sample_rate(ost->st, ost->enc);\\n\\n                codec->time_base = (AVRational){1, codec->sample_rate};\\n\\n                if (codec->sample_fmt == AV_SAMPLE_FMT_NONE)\\n\\n                    codec->sample_fmt = icodec->sample_fmt;\\n\\n                choose_sample_fmt(ost->st, ost->enc);\\n\\n                if (!codec->channels) {\\n\\n                    codec->channels = icodec->channels;\\n\\n                    codec->channel_layout = icodec->channel_layout;\\n\\n                }\\n\\n                if (av_get_channel_layout_nb_channels(codec->channel_layout) != codec->channels)\\n\\n                    codec->channel_layout = 0;\\n\\n                ost->audio_resample = codec->sample_rate != icodec->sample_rate || audio_sync_method > 1;\\n\\n                icodec->request_channels = codec->channels;\\n\\n                ist->decoding_needed = 1;\\n\\n                ost->encoding_needed = 1;\\n\\n                ost->resample_sample_fmt  = icodec->sample_fmt;\\n\\n                ost->resample_sample_rate = icodec->sample_rate;\\n\\n                ost->resample_channels    = icodec->channels;\\n\\n                break;\\n\\n            case AVMEDIA_TYPE_VIDEO:\\n\\n                if (codec->pix_fmt == PIX_FMT_NONE)\\n\\n                    codec->pix_fmt = icodec->pix_fmt;\\n\\n                choose_pixel_fmt(ost->st, ost->enc);\\n\\n\\n\\n                if (ost->st->codec->pix_fmt == PIX_FMT_NONE) {\\n\\n                    fprintf(stderr, \\\"Video pixel format is unknown, stream cannot be encoded\\\\n\\\");\\n\\n                    ffmpeg_exit(1);\\n\\n                }\\n\\n                ost->video_resample = codec->width   != icodec->width  ||\\n\\n                                      codec->height  != icodec->height ||\\n\\n                                      codec->pix_fmt != icodec->pix_fmt;\\n\\n                if (ost->video_resample) {\\n\\n                    codec->bits_per_raw_sample= frame_bits_per_raw_sample;\\n\\n                }\\n\\n                if (!codec->width || !codec->height) {\\n\\n                    codec->width  = icodec->width;\\n\\n                    codec->height = icodec->height;\\n\\n                }\\n\\n                ost->resample_height = icodec->height;\\n\\n                ost->resample_width  = icodec->width;\\n\\n                ost->resample_pix_fmt= icodec->pix_fmt;\\n\\n                ost->encoding_needed = 1;\\n\\n                ist->decoding_needed = 1;\\n\\n\\n\\n                if (!ost->frame_rate.num)\\n\\n                    ost->frame_rate = ist->st->r_frame_rate.num ? ist->st->r_frame_rate : (AVRational){25,1};\\n\\n                if (ost->enc && ost->enc->supported_framerates && !force_fps) {\\n\\n                    int idx = av_find_nearest_q_idx(ost->frame_rate, ost->enc->supported_framerates);\\n\\n                    ost->frame_rate = ost->enc->supported_framerates[idx];\\n\\n                }\\n\\n                codec->time_base = (AVRational){ost->frame_rate.den, ost->frame_rate.num};\\n\\n                if(   av_q2d(codec->time_base) < 0.001 && video_sync_method\\n\\n                   && (video_sync_method==1 || (video_sync_method<0 && !(os->oformat->flags & AVFMT_VARIABLE_FPS)))){\\n\\n                    av_log(os, AV_LOG_WARNING, \\\"Frame rate very high for a muxer not effciciently supporting it.\\\\n\\\"\\n\\n                                               \\\"Please consider specifiying a lower framerate, a different muxer or -vsync 2\\\\n\\\");\\n\\n                }\\n\\n\\n\\n#if CONFIG_AVFILTER\\n\\n                if (configure_video_filters(ist, ost)) {\\n\\n                    fprintf(stderr, \\\"Error opening filters!\\\\n\\\");\\n\\n                    exit(1);\\n\\n                }\\n\\n#endif\\n\\n                break;\\n\\n            case AVMEDIA_TYPE_SUBTITLE:\\n\\n                ost->encoding_needed = 1;\\n\\n                ist->decoding_needed = 1;\\n\\n                break;\\n\\n            default:\\n\\n                abort();\\n\\n                break;\\n\\n            }\\n\\n            /* two pass mode */\\n\\n            if (ost->encoding_needed && codec->codec_id != CODEC_ID_H264 &&\\n\\n                (codec->flags & (CODEC_FLAG_PASS1 | CODEC_FLAG_PASS2))) {\\n\\n                char logfilename[1024];\\n\\n                FILE *f;\\n\\n\\n\\n                snprintf(logfilename, sizeof(logfilename), \\\"%s-%d.log\\\",\\n\\n                         pass_logfilename_prefix ? pass_logfilename_prefix : DEFAULT_PASS_LOGFILENAME_PREFIX,\\n\\n                         i);\\n\\n                if (codec->flags & CODEC_FLAG_PASS1) {\\n\\n                    f = fopen(logfilename, \\\"wb\\\");\\n\\n                    if (!f) {\\n\\n                        fprintf(stderr, \\\"Cannot write log file '%s' for pass-1 encoding: %s\\\\n\\\", logfilename, strerror(errno));\\n\\n                        ffmpeg_exit(1);\\n\\n                    }\\n\\n                    ost->logfile = f;\\n\\n                } else {\\n\\n                    char  *logbuffer;\\n\\n                    size_t logbuffer_size;\\n\\n                    if (read_file(logfilename, &logbuffer, &logbuffer_size) < 0) {\\n\\n                        fprintf(stderr, \\\"Error reading log file '%s' for pass-2 encoding\\\\n\\\", logfilename);\\n\\n                        ffmpeg_exit(1);\\n\\n                    }\\n\\n                    codec->stats_in = logbuffer;\\n\\n                }\\n\\n            }\\n\\n        }\\n\\n        if(codec->codec_type == AVMEDIA_TYPE_VIDEO){\\n\\n            /* maximum video buffer size is 6-bytes per pixel, plus DPX header size */\\n\\n            int size= codec->width * codec->height;\\n\\n            bit_buffer_size= FFMAX(bit_buffer_size, 6*size + 1664);\\n\\n        }\\n\\n    }\\n\\n\\n\\n    if (!bit_buffer)\\n\\n        bit_buffer = av_malloc(bit_buffer_size);\\n\\n    if (!bit_buffer) {\\n\\n        fprintf(stderr, \\\"Cannot allocate %d bytes output buffer\\\\n\\\",\\n\\n                bit_buffer_size);\\n\\n        ret = AVERROR(ENOMEM);\\n\\n        goto fail;\\n\\n    }\\n\\n\\n\\n    /* open each encoder */\\n\\n    for(i=0;i<nb_ostreams;i++) {\\n\\n        ost = ost_table[i];\\n\\n        if (ost->encoding_needed) {\\n\\n            AVCodec *codec = ost->enc;\\n\\n            AVCodecContext *dec = input_streams[ost->source_index].st->codec;\\n\\n            if (!codec) {\\n\\n                snprintf(error, sizeof(error), \\\"Encoder (codec id %d) not found for output stream #%d.%d\\\",\\n\\n                         ost->st->codec->codec_id, ost->file_index, ost->index);\\n\\n                ret = AVERROR(EINVAL);\\n\\n                goto dump_format;\\n\\n            }\\n\\n            if (dec->subtitle_header) {\\n\\n                ost->st->codec->subtitle_header = av_malloc(dec->subtitle_header_size);\\n\\n                if (!ost->st->codec->subtitle_header) {\\n\\n                    ret = AVERROR(ENOMEM);\\n\\n                    goto dump_format;\\n\\n                }\\n\\n                memcpy(ost->st->codec->subtitle_header, dec->subtitle_header, dec->subtitle_header_size);\\n\\n                ost->st->codec->subtitle_header_size = dec->subtitle_header_size;\\n\\n            }\\n\\n            if (avcodec_open2(ost->st->codec, codec, &ost->opts) < 0) {\\n\\n                snprintf(error, sizeof(error), \\\"Error while opening encoder for output stream #%d.%d - maybe incorrect parameters such as bit_rate, rate, width or height\\\",\\n\\n                        ost->file_index, ost->index);\\n\\n                ret = AVERROR(EINVAL);\\n\\n                goto dump_format;\\n\\n            }\\n\\n            assert_codec_experimental(ost->st->codec, 1);\\n\\n            assert_avoptions(ost->opts);\\n\\n            if (ost->st->codec->bit_rate && ost->st->codec->bit_rate < 1000)\\n\\n                av_log(NULL, AV_LOG_WARNING, \\\"The bitrate parameter is set too low.\\\"\\n\\n                                             \\\"It takes bits/s as argument, not kbits/s\\\\n\\\");\\n\\n            extra_size += ost->st->codec->extradata_size;\\n\\n        }\\n\\n    }\\n\\n\\n\\n    /* open each decoder */\\n\\n    for (i = 0; i < nb_input_streams; i++) {\\n\\n        ist = &input_streams[i];\\n\\n        if (ist->decoding_needed) {\\n\\n            AVCodec *codec = ist->dec;\\n\\n            if (!codec)\\n\\n                codec = avcodec_find_decoder(ist->st->codec->codec_id);\\n\\n            if (!codec) {\\n\\n                snprintf(error, sizeof(error), \\\"Decoder (codec id %d) not found for input stream #%d.%d\\\",\\n\\n                        ist->st->codec->codec_id, ist->file_index, ist->st->index);\\n\\n                ret = AVERROR(EINVAL);\\n\\n                goto dump_format;\\n\\n            }\\n\\n            if (avcodec_open2(ist->st->codec, codec, &ist->opts) < 0) {\\n\\n                snprintf(error, sizeof(error), \\\"Error while opening decoder for input stream #%d.%d\\\",\\n\\n                        ist->file_index, ist->st->index);\\n\\n                ret = AVERROR(EINVAL);\\n\\n                goto dump_format;\\n\\n            }\\n\\n            assert_codec_experimental(ist->st->codec, 0);\\n\\n            assert_avoptions(ost->opts);\\n\\n            //if (ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO)\\n\\n            //    ist->st->codec->flags |= CODEC_FLAG_REPEAT_FIELD;\\n\\n        }\\n\\n    }\\n\\n\\n\\n    /* init pts */\\n\\n    for (i = 0; i < nb_input_streams; i++) {\\n\\n        AVStream *st;\\n\\n        ist = &input_streams[i];\\n\\n        st= ist->st;\\n\\n        ist->pts = st->avg_frame_rate.num ? - st->codec->has_b_frames*AV_TIME_BASE / av_q2d(st->avg_frame_rate) : 0;\\n\\n        ist->next_pts = AV_NOPTS_VALUE;\\n\\n        ist->is_start = 1;\\n\\n    }\\n\\n\\n\\n    /* set meta data information from input file if required */\\n\\n    for (i=0;i<nb_meta_data_maps;i++) {\\n\\n        AVFormatContext *files[2];\\n\\n        AVDictionary    **meta[2];\\n\\n        int j;\\n\\n\\n\\n#define METADATA_CHECK_INDEX(index, nb_elems, desc)\\\\\\n\\n        if ((index) < 0 || (index) >= (nb_elems)) {\\\\\\n\\n            snprintf(error, sizeof(error), \\\"Invalid %s index %d while processing metadata maps\\\\n\\\",\\\\\\n\\n                     (desc), (index));\\\\\\n\\n            ret = AVERROR(EINVAL);\\\\\\n\\n            goto dump_format;\\\\\\n\\n        }\\n\\n\\n\\n        int out_file_index = meta_data_maps[i][0].file;\\n\\n        int in_file_index = meta_data_maps[i][1].file;\\n\\n        if (in_file_index < 0 || out_file_index < 0)\\n\\n            continue;\\n\\n        METADATA_CHECK_INDEX(out_file_index, nb_output_files, \\\"output file\\\")\\n\\n        METADATA_CHECK_INDEX(in_file_index, nb_input_files, \\\"input file\\\")\\n\\n\\n\\n        files[0] = output_files[out_file_index];\\n\\n        files[1] = input_files[in_file_index].ctx;\\n\\n\\n\\n        for (j = 0; j < 2; j++) {\\n\\n            MetadataMap *map = &meta_data_maps[i][j];\\n\\n\\n\\n            switch (map->type) {\\n\\n            case 'g':\\n\\n                meta[j] = &files[j]->metadata;\\n\\n                break;\\n\\n            case 's':\\n\\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_streams, \\\"stream\\\")\\n\\n                meta[j] = &files[j]->streams[map->index]->metadata;\\n\\n                break;\\n\\n            case 'c':\\n\\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_chapters, \\\"chapter\\\")\\n\\n                meta[j] = &files[j]->chapters[map->index]->metadata;\\n\\n                break;\\n\\n            case 'p':\\n\\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_programs, \\\"program\\\")\\n\\n                meta[j] = &files[j]->programs[map->index]->metadata;\\n\\n                break;\\n\\n            }\\n\\n        }\\n\\n\\n\\n        av_dict_copy(meta[0], *meta[1], AV_DICT_DONT_OVERWRITE);\\n\\n    }\\n\\n\\n\\n    /* copy global metadata by default */\\n\\n    if (metadata_global_autocopy) {\\n\\n\\n\\n        for (i = 0; i < nb_output_files; i++)\\n\\n            av_dict_copy(&output_files[i]->metadata, input_files[0].ctx->metadata,\\n\\n                         AV_DICT_DONT_OVERWRITE);\\n\\n    }\\n\\n\\n\\n    /* copy chapters according to chapter maps */\\n\\n    for (i = 0; i < nb_chapter_maps; i++) {\\n\\n        int infile  = chapter_maps[i].in_file;\\n\\n        int outfile = chapter_maps[i].out_file;\\n\\n\\n\\n        if (infile < 0 || outfile < 0)\\n\\n            continue;\\n\\n        if (infile >= nb_input_files) {\\n\\n            snprintf(error, sizeof(error), \\\"Invalid input file index %d in chapter mapping.\\\\n\\\", infile);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto dump_format;\\n\\n        }\\n\\n        if (outfile >= nb_output_files) {\\n\\n            snprintf(error, sizeof(error), \\\"Invalid output file index %d in chapter mapping.\\\\n\\\",outfile);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto dump_format;\\n\\n        }\\n\\n        copy_chapters(infile, outfile);\\n\\n    }\\n\\n\\n\\n    /* copy chapters from the first input file that has them*/\\n\\n    if (!nb_chapter_maps)\\n\\n        for (i = 0; i < nb_input_files; i++) {\\n\\n            if (!input_files[i].ctx->nb_chapters)\\n\\n                continue;\\n\\n\\n\\n            for (j = 0; j < nb_output_files; j++)\\n\\n                if ((ret = copy_chapters(i, j)) < 0)\\n\\n                    goto dump_format;\\n\\n            break;\\n\\n        }\\n\\n\\n\\n    /* open files and write file headers */\\n\\n    for(i=0;i<nb_output_files;i++) {\\n\\n        os = output_files[i];\\n\\n        if (avformat_write_header(os, &output_opts[i]) < 0) {\\n\\n            snprintf(error, sizeof(error), \\\"Could not write header for output file #%d (incorrect codec parameters ?)\\\", i);\\n\\n            ret = AVERROR(EINVAL);\\n\\n            goto dump_format;\\n\\n        }\\n\\n        assert_avoptions(output_opts[i]);\\n\\n        if (strcmp(output_files[i]->oformat->name, \\\"rtp\\\")) {\\n\\n            want_sdp = 0;\\n\\n        }\\n\\n    }\\n\\n\\n\\n dump_format:\\n\\n    /* dump the file output parameters - cannot be done before in case\\n\\n       of stream copy */\\n\\n    for(i=0;i<nb_output_files;i++) {\\n\\n        av_dump_format(output_files[i], i, output_files[i]->filename, 1);\\n\\n    }\\n\\n\\n\\n    /* dump the stream mapping */\\n\\n    if (verbose >= 0) {\\n\\n        fprintf(stderr, \\\"Stream mapping:\\\\n\\\");\\n\\n        for(i=0;i<nb_ostreams;i++) {\\n\\n            ost = ost_table[i];\\n\\n            fprintf(stderr, \\\"  Stream #%d.%d -> #%d.%d\\\",\\n\\n                    input_streams[ost->source_index].file_index,\\n\\n                    input_streams[ost->source_index].st->index,\\n\\n                    ost->file_index,\\n\\n                    ost->index);\\n\\n            if (ost->sync_ist != &input_streams[ost->source_index])\\n\\n                fprintf(stderr, \\\" [sync #%d.%d]\\\",\\n\\n                        ost->sync_ist->file_index,\\n\\n                        ost->sync_ist->st->index);\\n\\n            fprintf(stderr, \\\"\\\\n\\\");\\n\\n        }\\n\\n    }\\n\\n\\n\\n    if (ret) {\\n\\n        fprintf(stderr, \\\"%s\\\\n\\\", error);\\n\\n        goto fail;\\n\\n    }\\n\\n\\n\\n    if (want_sdp) {\\n\\n        print_sdp(output_files, nb_output_files);\\n\\n    }\\n\\n\\n\\n    if (!using_stdin) {\\n\\n        if(verbose >= 0)\\n\\n            fprintf(stderr, \\\"Press [q] to stop, [?] for help\\\\n\\\");\\n\\n        avio_set_interrupt_cb(decode_interrupt_cb);\\n\\n    }\\n\\n    term_init();\\n\\n\\n\\n    timer_start = av_gettime();\\n\\n\\n\\n    for(; received_sigterm == 0;) {\\n\\n        int file_index, ist_index;\\n\\n        AVPacket pkt;\\n\\n        double ipts_min;\\n\\n        double opts_min;\\n\\n\\n\\n    redo:\\n\\n        ipts_min= 1e100;\\n\\n        opts_min= 1e100;\\n\\n        /* if 'q' pressed, exits */\\n\\n        if (!using_stdin) {\\n\\n            if (q_pressed)\\n\\n                break;\\n\\n            /* read_key() returns 0 on EOF */\\n\\n            key = read_key();\\n\\n            if (key == 'q')\\n\\n                break;\\n\\n            if (key == '+') verbose++;\\n\\n            if (key == '-') verbose--;\\n\\n            if (key == 's') qp_hist     ^= 1;\\n\\n            if (key == 'h'){\\n\\n                if (do_hex_dump){\\n\\n                    do_hex_dump = do_pkt_dump = 0;\\n\\n                } else if(do_pkt_dump){\\n\\n                    do_hex_dump = 1;\\n\\n                } else\\n\\n                    do_pkt_dump = 1;\\n\\n                av_log_set_level(AV_LOG_DEBUG);\\n\\n            }\\n\\n            if (key == 'd' || key == 'D'){\\n\\n                int debug=0;\\n\\n                if(key == 'D') {\\n\\n                    debug = input_streams[0].st->codec->debug<<1;\\n\\n                    if(!debug) debug = 1;\\n\\n                    while(debug & (FF_DEBUG_DCT_COEFF|FF_DEBUG_VIS_QP|FF_DEBUG_VIS_MB_TYPE)) //unsupported, would just crash\\n\\n                        debug += debug;\\n\\n                }else\\n\\n                    scanf(\\\"%d\\\", &debug);\\n\\n                for(i=0;i<nb_input_streams;i++) {\\n\\n                    input_streams[i].st->codec->debug = debug;\\n\\n                }\\n\\n                for(i=0;i<nb_ostreams;i++) {\\n\\n                    ost = ost_table[i];\\n\\n                    ost->st->codec->debug = debug;\\n\\n                }\\n\\n                if(debug) av_log_set_level(AV_LOG_DEBUG);\\n\\n                fprintf(stderr,\\\"debug=%d\\\\n\\\", debug);\\n\\n            }\\n\\n            if (key == '?'){\\n\\n                fprintf(stderr, \\\"key    function\\\\n\\\"\\n\\n                                \\\"?      show this help\\\\n\\\"\\n\\n                                \\\"+      increase verbosity\\\\n\\\"\\n\\n                                \\\"-      decrease verbosity\\\\n\\\"\\n\\n                                \\\"D      cycle through available debug modes\\\\n\\\"\\n\\n                                \\\"h      dump packets/hex press to cycle through the 3 states\\\\n\\\"\\n\\n                                \\\"q      quit\\\\n\\\"\\n\\n                                \\\"s      Show QP histogram\\\\n\\\"\\n\\n                );\\n\\n            }\\n\\n        }\\n\\n\\n\\n        /* select the stream that we must read now by looking at the\\n\\n           smallest output pts */\\n\\n        file_index = -1;\\n\\n        for(i=0;i<nb_ostreams;i++) {\\n\\n            double ipts, opts;\\n\\n            ost = ost_table[i];\\n\\n            os = output_files[ost->file_index];\\n\\n            ist = &input_streams[ost->source_index];\\n\\n            if(ist->is_past_recording_time || no_packet[ist->file_index])\\n\\n                continue;\\n\\n                opts = ost->st->pts.val * av_q2d(ost->st->time_base);\\n\\n            ipts = (double)ist->pts;\\n\\n            if (!input_files[ist->file_index].eof_reached){\\n\\n                if(ipts < ipts_min) {\\n\\n                    ipts_min = ipts;\\n\\n                    if(input_sync ) file_index = ist->file_index;\\n\\n                }\\n\\n                if(opts < opts_min) {\\n\\n                    opts_min = opts;\\n\\n                    if(!input_sync) file_index = ist->file_index;\\n\\n                }\\n\\n            }\\n\\n            if(ost->frame_number >= max_frames[ost->st->codec->codec_type]){\\n\\n                file_index= -1;\\n\\n                break;\\n\\n            }\\n\\n        }\\n\\n        /* if none, if is finished */\\n\\n        if (file_index < 0) {\\n\\n            if(no_packet_count){\\n\\n                no_packet_count=0;\\n\\n                memset(no_packet, 0, sizeof(no_packet));\\n\\n                usleep(10000);\\n\\n                continue;\\n\\n            }\\n\\n            break;\\n\\n        }\\n\\n\\n\\n        /* finish if limit size exhausted */\\n\\n        if (limit_filesize != 0 && limit_filesize <= avio_tell(output_files[0]->pb))\\n\\n            break;\\n\\n\\n\\n        /* read a frame from it and output it in the fifo */\\n\\n        is = input_files[file_index].ctx;\\n\\n        ret= av_read_frame(is, &pkt);\\n\\n        if(ret == AVERROR(EAGAIN)){\\n\\n            no_packet[file_index]=1;\\n\\n            no_packet_count++;\\n\\n            continue;\\n\\n        }\\n\\n        if (ret < 0) {\\n\\n            input_files[file_index].eof_reached = 1;\\n\\n            if (opt_shortest)\\n\\n                break;\\n\\n            else\\n\\n                continue;\\n\\n        }\\n\\n\\n\\n        no_packet_count=0;\\n\\n        memset(no_packet, 0, sizeof(no_packet));\\n\\n\\n\\n        if (do_pkt_dump) {\\n\\n            av_pkt_dump_log2(NULL, AV_LOG_DEBUG, &pkt, do_hex_dump,\\n\\n                             is->streams[pkt.stream_index]);\\n\\n        }\\n\\n        /* the following test is needed in case new streams appear\\n\\n           dynamically in stream : we ignore them */\\n\\n        if (pkt.stream_index >= input_files[file_index].ctx->nb_streams)\\n\\n            goto discard_packet;\\n\\n        ist_index = input_files[file_index].ist_index + pkt.stream_index;\\n\\n        ist = &input_streams[ist_index];\\n\\n        if (ist->discard)\\n\\n            goto discard_packet;\\n\\n\\n\\n        if (pkt.dts != AV_NOPTS_VALUE)\\n\\n            pkt.dts += av_rescale_q(input_files[ist->file_index].ts_offset, AV_TIME_BASE_Q, ist->st->time_base);\\n\\n        if (pkt.pts != AV_NOPTS_VALUE)\\n\\n            pkt.pts += av_rescale_q(input_files[ist->file_index].ts_offset, AV_TIME_BASE_Q, ist->st->time_base);\\n\\n\\n\\n        if (ist->ts_scale) {\\n\\n            if(pkt.pts != AV_NOPTS_VALUE)\\n\\n                pkt.pts *= ist->ts_scale;\\n\\n            if(pkt.dts != AV_NOPTS_VALUE)\\n\\n                pkt.dts *= ist->ts_scale;\\n\\n        }\\n\\n\\n\\n//        fprintf(stderr, \\\"next:%\\\"PRId64\\\" dts:%\\\"PRId64\\\" off:%\\\"PRId64\\\" %d\\\\n\\\", ist->next_pts, pkt.dts, input_files[ist->file_index].ts_offset, ist->st->codec->codec_type);\\n\\n        if (pkt.dts != AV_NOPTS_VALUE && ist->next_pts != AV_NOPTS_VALUE\\n\\n            && (is->iformat->flags & AVFMT_TS_DISCONT)) {\\n\\n            int64_t pkt_dts= av_rescale_q(pkt.dts, ist->st->time_base, AV_TIME_BASE_Q);\\n\\n            int64_t delta= pkt_dts - ist->next_pts;\\n\\n            if((FFABS(delta) > 1LL*dts_delta_threshold*AV_TIME_BASE || pkt_dts+1<ist->pts)&& !copy_ts){\\n\\n                input_files[ist->file_index].ts_offset -= delta;\\n\\n                if (verbose > 2)\\n\\n                    fprintf(stderr, \\\"timestamp discontinuity %\\\"PRId64\\\", new offset= %\\\"PRId64\\\"\\\\n\\\",\\n\\n                            delta, input_files[ist->file_index].ts_offset);\\n\\n                pkt.dts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\\n\\n                if(pkt.pts != AV_NOPTS_VALUE)\\n\\n                    pkt.pts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\\n\\n            }\\n\\n        }\\n\\n\\n\\n        /* finish if recording time exhausted */\\n\\n        if (recording_time != INT64_MAX &&\\n\\n            (pkt.pts != AV_NOPTS_VALUE ?\\n\\n                av_compare_ts(pkt.pts, ist->st->time_base, recording_time + start_time, (AVRational){1, 1000000})\\n\\n                    :\\n\\n                av_compare_ts(ist->pts, AV_TIME_BASE_Q, recording_time + start_time, (AVRational){1, 1000000})\\n\\n            )>= 0) {\\n\\n            ist->is_past_recording_time = 1;\\n\\n            goto discard_packet;\\n\\n        }\\n\\n\\n\\n        //fprintf(stderr,\\\"read #%d.%d size=%d\\\\n\\\", ist->file_index, ist->st->index, pkt.size);\\n\\n        if (output_packet(ist, ist_index, ost_table, nb_ostreams, &pkt) < 0) {\\n\\n\\n\\n            if (verbose >= 0)\\n\\n                fprintf(stderr, \\\"Error while decoding stream #%d.%d\\\\n\\\",\\n\\n                        ist->file_index, ist->st->index);\\n\\n            if (exit_on_error)\\n\\n                ffmpeg_exit(1);\\n\\n            av_free_packet(&pkt);\\n\\n            goto redo;\\n\\n        }\\n\\n\\n\\n    discard_packet:\\n\\n        av_free_packet(&pkt);\\n\\n\\n\\n        /* dump report by using the output first video and audio streams */\\n\\n        print_report(output_files, ost_table, nb_ostreams, 0);\\n\\n    }\\n\\n\\n\\n    /* at the end of stream, we must flush the decoder buffers */\\n\\n    for (i = 0; i < nb_input_streams; i++) {\\n\\n        ist = &input_streams[i];\\n\\n        if (ist->decoding_needed) {\\n\\n            output_packet(ist, i, ost_table, nb_ostreams, NULL);\\n\\n        }\\n\\n    }\\n\\n\\n\\n    term_exit();\\n\\n\\n\\n    /* write the trailer if needed and close file */\\n\\n    for(i=0;i<nb_output_files;i++) {\\n\\n        os = output_files[i];\\n\\n        av_write_trailer(os);\\n\\n    }\\n\\n\\n\\n    /* dump report by using the first video and audio streams */\\n\\n    print_report(output_files, ost_table, nb_ostreams, 1);\\n\\n\\n\\n    /* close each encoder */\\n\\n    for(i=0;i<nb_ostreams;i++) {\\n\\n        ost = ost_table[i];\\n\\n        if (ost->encoding_needed) {\\n\\n            av_freep(&ost->st->codec->stats_in);\\n\\n            avcodec_close(ost->st->codec);\\n\\n        }\\n\\n#if CONFIG_AVFILTER\\n\\n        avfilter_graph_free(&ost->graph);\\n\\n#endif\\n\\n    }\\n\\n\\n\\n    /* close each decoder */\\n\\n    for (i = 0; i < nb_input_streams; i++) {\\n\\n        ist = &input_streams[i];\\n\\n        if (ist->decoding_needed) {\\n\\n            avcodec_close(ist->st->codec);\\n\\n        }\\n\\n    }\\n\\n\\n\\n    /* finished ! */\\n\\n    ret = 0;\\n\\n\\n\\n fail:\\n\\n    av_freep(&bit_buffer);\\n\\n\\n\\n    if (ost_table) {\\n\\n        for(i=0;i<nb_ostreams;i++) {\\n\\n            ost = ost_table[i];\\n\\n            if (ost) {\\n\\n                if (ost->st->stream_copy)\\n\\n                    av_freep(&ost->st->codec->extradata);\\n\\n                if (ost->logfile) {\\n\\n                    fclose(ost->logfile);\\n\\n                    ost->logfile = NULL;\\n\\n                }\\n\\n                av_fifo_free(ost->fifo); /* works even if fifo is not\\n\\n                                             initialized but set to zero */\\n\\n                av_freep(&ost->st->codec->subtitle_header);\\n\\n                av_free(ost->resample_frame.data[0]);\\n\\n                av_free(ost->forced_kf_pts);\\n\\n                if (ost->video_resample)\\n\\n                    sws_freeContext(ost->img_resample_ctx);\\n\\n                if (ost->resample)\\n\\n                    audio_resample_close(ost->resample);\\n\\n                if (ost->reformat_ctx)\\n\\n                    av_audio_convert_free(ost->reformat_ctx);\\n\\n                av_dict_free(&ost->opts);\\n\\n                av_free(ost);\\n\\n            }\\n\\n        }\\n\\n        av_free(ost_table);\\n\\n    }\\n\\n    return ret;\\n\\n}\\n\",\n          \"int av_opencl_buffer_write(cl_mem dst_cl_buf, uint8_t *src_buf, size_t buf_size)\\n\\n{\\n\\n    cl_int status;\\n\\n    void *mapped = clEnqueueMapBuffer(gpu_env.command_queue, dst_cl_buf,\\n\\n                                      CL_TRUE,CL_MAP_WRITE, 0, sizeof(uint8_t) * buf_size,\\n\\n                                      0, NULL, NULL, &status);\\n\\n\\n\\n    if (status != CL_SUCCESS) {\\n\\n        av_log(&openclutils, AV_LOG_ERROR, \\\"Could not map OpenCL buffer: %s\\\\n\\\", opencl_errstr(status));\\n\\n        return AVERROR_EXTERNAL;\\n\\n    }\\n\\n    memcpy(mapped, src_buf, buf_size);\\n\\n\\n\\n    status = clEnqueueUnmapMemObject(gpu_env.command_queue, dst_cl_buf, mapped, 0, NULL, NULL);\\n\\n    if (status != CL_SUCCESS) {\\n\\n        av_log(&openclutils, AV_LOG_ERROR, \\\"Could not unmap OpenCL buffer: %s\\\\n\\\", opencl_errstr(status));\\n\\n        return AVERROR_EXTERNAL;\\n\\n    }\\n\\n    return 0;\\n\\n}\\n\",\n          \"static void v4l2_free_buffer(void *opaque, uint8_t *unused)\\n\\n{\\n\\n    V4L2Buffer* avbuf = opaque;\\n\\n    V4L2m2mContext *s = buf_to_m2mctx(avbuf);\\n\\n\\n\\n    if (atomic_fetch_sub(&avbuf->context_refcount, 1) == 1) {\\n\\n        atomic_fetch_sub_explicit(&s->refcount, 1, memory_order_acq_rel);\\n\\n\\n\\n        if (s->reinit) {\\n\\n            if (!atomic_load(&s->refcount))\\n\\n                sem_post(&s->refsync);\\n\\n        } else if (avbuf->context->streamon)\\n\\n            ff_v4l2_buffer_enqueue(avbuf);\\n\\n\\n\\n        av_buffer_unref(&avbuf->context_ref);\\n\\n    }\\n\\n}\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[0, 42653, 6979, 6214, 20414, 1640, 10612, 48587, 48522, 13540, 46234, 1215, 42018, 6, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 6979, 295, 428, 1215, 46234, 1215, 42018, 6, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 41327, 9966, 1009, 46797, 1215, 42018, 6, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 6979, 295, 428, 1215, 46797, 1215, 42018, 6, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 16183, 41151, 1009, 8656, 1215, 44754, 6, 6979, 295, 428, 1215, 8656, 1215, 44754, 43, 50118, 50118, 45152, 50140, 1437, 1437, 1437, 6979, 5494, 5457, 321, 6, 939, 6, 1236, 6, 449, 6, 295, 6, 295, 428, 1215, 2603, 26930, 29, 5457, 321, 6, 1149, 131, 50140, 50140, 1437, 1437, 1437, 17307, 48587, 48522, 1009, 354, 6, 1009, 366, 131, 50140, 1437, 1437, 1437, 17307, 47436, 3204, 48522, 1009, 29659, 3204, 6, 1009, 636, 1630, 3204, 131, 50140, 1437, 1437, 1437, 38252, 36757, 1009, 2603, 6, 13540, 2603, 1215, 14595, 5457, 48955, 131, 50140, 1437, 1437, 1437, 41327, 36757, 1009, 661, 131, 50140, 1437, 1437, 1437, 16224, 5849, 10975, 47477, 44082, 50140, 1437, 1437, 1437, 6979, 762, 131, 50140, 1437, 1437, 1437, 6979, 236, 1215, 28045, 642, 5457, 112, 131, 50140, 1437, 1437, 1437, 2]\",\n          \"[0, 2544, 6402, 1215, 12592, 3998, 1215, 47438, 1215, 29631, 1640, 3998, 1215, 25683, 49339, 1215, 3998, 1215, 48939, 6, 49315, 398, 1215, 90, 1009, 45692, 1215, 48939, 6, 1836, 1215, 90, 49125, 1215, 10799, 43, 50118, 50118, 45152, 50140, 1437, 1437, 1437, 3741, 1215, 2544, 2194, 131, 50140, 1437, 1437, 1437, 13842, 1009, 119, 11251, 5457, 3741, 16040, 48702, 41151, 49334, 1640, 49375, 1215, 41124, 4, 41483, 1215, 48702, 6, 49339, 1215, 3998, 1215, 48939, 6, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 5289, 1215, 6997, 9162, 6, 7454, 1215, 43861, 1215, 19839, 12946, 6, 321, 6, 49907, 1640, 47157, 398, 1215, 90, 43, 1009, 49125, 1215, 10799, 6, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 321, 6, 48955, 6, 48955, 6, 359, 29552, 4397, 50140, 50140, 1437, 1437, 1437, 114, 36, 29552, 49333, 5289, 1215, 10466, 3376, 12147, 43, 25522, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 6402, 1215, 12376, 49763, 12592, 3998, 49320, 6, 17307, 1215, 45403, 1215, 46734, 6, 22, 35299, 45, 5456, 2117, 7454, 21944, 35, 7606, 29, 37457, 282, 1297, 490, 3998, 1215, 14385, 6031, 1640, 29552, 48749, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2]\",\n          \"[0, 42653, 13842, 748, 306, 462, 176, 1215, 3743, 1215, 47438, 1640, 47908, 1009, 1517, 35485, 6, 49315, 398, 1215, 90, 1009, 879, 6199, 43, 50118, 50118, 45152, 50140, 1437, 1437, 1437, 468, 306, 574, 176, 49334, 3226, 6402, 48939, 5457, 31861, 131, 50140, 1437, 1437, 1437, 468, 306, 574, 176, 119, 176, 119, 48522, 1009, 29, 5457, 49125, 1215, 560, 1215, 119, 176, 119, 49575, 1640, 1469, 48939, 4397, 50140, 50140, 1437, 1437, 1437, 114, 36, 45826, 1215, 506, 29094, 1215, 10936, 49763, 1469, 48939, 46613, 46796, 1215, 13043, 11432, 6, 112, 43, 45994, 112, 43, 25522, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 21495, 1215, 506, 29094, 1215, 10936, 1215, 23242, 17022, 49763, 29, 46613, 13043, 11432, 6, 112, 6, 3783, 1215, 10337, 1215, 1043, 1343, 1215, 5982, 4397, 50140, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 36, 29, 46613, 241, 25153, 43, 25522, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 114, 48209, 45826, 1215, 16204, 49763, 29, 46613, 13043, 11432, 35122, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 9031, 1215, 7049, 49763, 29, 46613, 13043, 45176, 4397, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 35524, 1493, 114, 36, 1469, 48939, 46613, 46796, 46613, 8656, 261, 43, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 48400, 1215, 705, 306, 462, 176, 1215, 47438, 1215, 225, 48702, 1640, 1469, 48939, 4397, 50140, 50140, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 6402, 1215, 2]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pycparser import c_parser, c_ast\n",
        "import networkx as nx\n",
        "\n",
        "parser = c_parser.CParser()\n",
        "\n",
        "def ast_to_graph(ast_node, graph=None, parent=None):\n",
        "    if graph is None:\n",
        "        graph = nx.DiGraph()\n",
        "\n",
        "    node_id = id(ast_node)\n",
        "    label = type(ast_node).__name__\n",
        "    graph.add_node(node_id, label=label)\n",
        "\n",
        "    if parent:\n",
        "        graph.add_edge(parent, node_id)\n",
        "\n",
        "    for _, child in ast_node.children():\n",
        "        ast_to_graph(child, graph, node_id)\n",
        "\n",
        "    return graph"
      ],
      "metadata": {
        "id": "hFC7CeO9NMBf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_code = df.iloc[0]['code']\n",
        "try:\n",
        "    ast = parser.parse(sample_code)\n",
        "    G = ast_to_graph(ast)\n",
        "\n",
        "    print(\"Graph created with\", len(G.nodes), \"nodes and\", len(G.edges), \"edges.\")\n",
        "except Exception as e:\n",
        "    print(\"Parsing failed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "P3x69M6FNQB9",
        "outputId": "681f479d-a8d4-45fd-ce6e-c7479ef40db7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing failed: :1:16: before: int\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def sanitize_c_code(code):\n",
        "    # Replace common external types with dummy types\n",
        "    replacements = {\n",
        "        r'AVCodecContext': 'int',\n",
        "        r'AVFormatContext': 'int',\n",
        "        r'cl_mem': 'int',\n",
        "        r'uint8_t': 'unsigned char',\n",
        "        r'int64_t': 'long',\n",
        "        r'uint32_t': 'unsigned int',\n",
        "        r'void\\s*\\*': 'int*',  # void* → int*\n",
        "        r'__attribute__\\s*\\(\\(.*?\\)\\)': '',  # Remove GCC attributes\n",
        "    }\n",
        "\n",
        "    for pattern, repl in replacements.items():\n",
        "        code = re.sub(pattern, repl, code)\n",
        "\n",
        "    return code\n"
      ],
      "metadata": {
        "id": "k59YrhhVOEF4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_code = sanitize_c_code(df.iloc[0]['code'])\n",
        "\n",
        "try:\n",
        "    ast = parser.parse(sample_code)\n",
        "    G = ast_to_graph(ast)\n",
        "    print(\"Graph created with\", len(G.nodes), \"nodes and\", len(G.edges), \"edges.\")\n",
        "except Exception as e:\n",
        "    print(\"Parsing still failed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a2ITlFG3ONmz",
        "outputId": "ed448900-191c-4d02-ff79-cf347708fab3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing still failed: :1:16: before: int\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch Geometric and its dependencies (this takes ~2 mins)\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.2+cpu.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.2.2+cpu.html\n",
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jlsc0qZWOSE0",
        "outputId": "2dc3d1c8-b26e-498a-fa98-5f983dac33c4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.2.2+cpu.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt22cu121)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.2+cpu.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt22cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.16.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "\n",
        "graph_list = []\n",
        "# Use the calculated new_vocab_size\n",
        "vocab_size = new_vocab_size\n",
        "\n",
        "skipped_single_node = 0\n",
        "skipped_invalid_tokens = 0\n",
        "\n",
        "# Loop through each row of the dataset\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        input_ids = ast.literal_eval(row['input_ids'])\n",
        "        label = int(row['label'])\n",
        "\n",
        "        num_nodes = len(input_ids)\n",
        "\n",
        "        # Skip graphs with only one node, as the current edge creation doesn't handle this\n",
        "        if num_nodes <= 1:\n",
        "            skipped_single_node += 1\n",
        "            continue\n",
        "\n",
        "        # Check for invalid token IDs\n",
        "        if any(token_id >= vocab_size or token_id < 0 for token_id in input_ids):\n",
        "             skipped_invalid_tokens += 1\n",
        "             continue\n",
        "\n",
        "\n",
        "        # Create edges: connect each token to the next (i → i+1)\n",
        "        edge_index = torch.tensor([[i, i+1] for i in range(num_nodes - 1)], dtype=torch.long).t().contiguous()\n",
        "        edge_index = torch.cat([edge_index, edge_index[[1, 0]]], dim=1)  # make edges bidirectional\n",
        "\n",
        "        x = torch.tensor([[token_id] for token_id in input_ids], dtype=torch.long)  # shape: [num_nodes, 1]\n",
        "        y = torch.tensor([label], dtype=torch.long)\n",
        "\n",
        "        data = Data(x=x, edge_index=edge_index, y=y)\n",
        "        graph_list.append(data)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping row {idx} due to error: {e}\")\n",
        "\n",
        "print(f\"Skipped {skipped_single_node} graphs with a single node.\")\n",
        "print(f\"Skipped {skipped_invalid_tokens} graphs with invalid token IDs (>= {vocab_size} or < 0).\")\n",
        "print(f\"Successfully created {len(graph_list)} graphs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GIW7UyfhO9ph",
        "outputId": "c9a805ae-04e9-40ea-8a2e-1800b9822bcc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27318/27318 [00:23<00:00, 1182.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped 0 graphs with a single node.\n",
            "Skipped 0 graphs with invalid token IDs (>= 50247 or < 0).\n",
            "Successfully created 27318 graphs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train/val/test (80/10/10)\n",
        "train_graphs, temp_graphs = train_test_split(graph_list, test_size=0.2, random_state=42)\n",
        "val_graphs, test_graphs = train_test_split(temp_graphs, test_size=0.5, random_state=42)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_graphs, batch_size=32)\n",
        "test_loader = DataLoader(test_graphs, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9Fcn5tUYPfua",
        "outputId": "09fcf578-a48c-4623-821a-b4ea2482609c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "import torch.nn as nn\n",
        "\n",
        "class GCNClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=1, hidden_dim=64, num_classes=2):\n",
        "        super(GCNClassifier, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x.float(), data.edge_index, data.batch\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "hK9AI3wuP0Gp"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Use the GCNModel defined in cell vIMZSkbVTNj7 which includes an embedding layer\n",
        "model = GCNModel().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# Use the weighted loss function defined in cell SKsah_f7TA8G\n",
        "loss_fn = criterion\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            pred = out.argmax(dim=1)\n",
        "            # Ensure data.y is on the same device as pred for comparison\n",
        "            correct += (pred == data.y.to(device)).sum().item()\n",
        "            total += data.num_graphs\n",
        "    return correct / total\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Debugging: Check labels in each batch\n",
        "        print(f\"Epoch {epoch}, Batch {i}: data.y unique values: {torch.unique(data.y)}\")\n",
        "        print(f\"Epoch {epoch}, Batch {i}: data.y max value: {torch.max(data.y)}\")\n",
        "        print(f\"Epoch {epoch}, Batch {i}: data.y shape: {data.y.shape}\")\n",
        "\n",
        "\n",
        "        out = model(data)\n",
        "        # Use the weighted loss function 'criterion'\n",
        "        loss = loss_fn(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    val_acc = evaluate(val_loader)\n",
        "    print(f\"Epoch {epoch:02d} | Loss: {total_loss:.4f} | Val Acc: {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "COyXBYfnQrGo",
        "outputId": "6a7a8d7d-7c41-4907-daff-2f163fc10359"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-60-1092930273.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Use the GCNModel defined in cell vIMZSkbVTNj7 which includes an embedding layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Use the weighted loss function defined in cell SKsah_f7TA8G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1149\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = evaluate(test_loader)\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "teCJCWgSQvJU",
        "outputId": "c23d35dd-3734-4617-c795-f18cef67bb9b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.4524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1).detach().cpu().tolist()\n",
        "        label = data.y.detach().cpu().tolist()\n",
        "        all_preds.extend(pred)\n",
        "        all_labels.extend(label)\n"
      ],
      "metadata": {
        "id": "efCusWfvREnE"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(classification_report(all_labels, all_preds, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3PpMNagERjtC",
        "outputId": "e7c7ea0d-0ddc-4034-ff99-4b8b9810a1c4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000      1496\n",
            "           1     0.4524    1.0000    0.6230      1236\n",
            "\n",
            "    accuracy                         0.4524      2732\n",
            "   macro avg     0.2262    0.5000    0.3115      2732\n",
            "weighted avg     0.2047    0.4524    0.2818      2732\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Safe\", \"Vulnerable\"], yticklabels=[\"Safe\", \"Vulnerable\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix (GCN)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "si3mEOadSSzx",
        "outputId": "e6115b7a-9ae0-4e7c-d15c-bfd7a058dd75"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAGJCAYAAADxMfswAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVCZJREFUeJzt3XdYFNf7NvB7l7IgHZRmBLECVixfxG4k1lgixqhE0RBNjMSCLSQqlkQisRujaQp2o0aixqjEhgVBUSxosBExKqAgIih93j/8Ma/roMJSRtn7k2uuK3vmzMwzGwyPz5xzRiEIggAiIiIiAEq5AyAiIqLXBxMDIiIiEjExICIiIhETAyIiIhIxMSAiIiIREwMiIiISMTEgIiIiERMDIiIiEjExICIiIhETA3qjXb16Fd26dYOZmRkUCgXCwsLK9fz//vsvFAoFQkJCyvW8b7LOnTujc+fO5XrOW7duwcDAAMePHy/X85a3Nm3aYOrUqXKHQVShmBhQmV2/fh2ffPIJ6tSpAwMDA5iamqJdu3ZYunQpnjx5UqHX9vHxwYULF/DNN99g3bp1aNWqVYVerzKNGDECCoUCpqamxX6PV69ehUKhgEKhwIIFC0p9/jt37mDWrFmIjY0th2jLZs6cOXB3d0e7du0k+44ePYpBgwahZs2a0NfXh5mZGdzd3TFnzhwkJycXe74dO3agZ8+eqF69OvT19WFvb49Bgwbh4MGDYp/Dhw+L319MTIzkHCNGjICxsbFa27Rp07BixQokJSWV8Y6JXl+6cgdAb7Y///wT77//PlQqFYYPH47GjRsjNzcXx44dw5QpUxAXF4effvqpQq795MkTREZG4quvvoKfn1+FXMPR0RFPnjyBnp5ehZz/VXR1dfH48WPs2rULgwYNUtu3YcMGGBgYIDs7W6Nz37lzB7Nnz0bt2rXRvHnzEh+3f/9+ja73Ivfu3UNoaChCQ0Ml+2bOnIm5c+eiTp06GDFiBOrUqYPs7GzExMRg4cKFCA0NxfXr18X+giDgo48+QkhICNzc3ODv7w9bW1vcvXsXO3bsQNeuXXH8+HG0bdtW7TqzZs3Crl27Xhlrv379YGpqih9++AFz5swp+80TvY4EIg3duHFDMDY2FpydnYU7d+5I9l+9elVYsmRJhV3/5s2bAgDhu+++q7BryMnHx0cwMjISunXrJvTv31+yv379+oKXl5fG38GpU6cEAMKaNWtK1D8rK6vU1yiJRYsWCYaGhsKjR4/U2jdv3iwAEAYNGiTk5ORIjktPTxcCAwPV2r777jsBgDBhwgShsLBQcszatWuFqKgoQRAE4dChQwIAoXnz5gIAISYmRq1v0ff/PD8/P8HR0bHY8xNVBUwMSGOffvqpAEA4fvx4ifrn5eUJc+bMEerUqSPo6+sLjo6OQkBAgJCdna3Wz9HRUejdu7dw9OhRoXXr1oJKpRKcnJyE0NBQsU9gYKAAQG1zdHQUBOHp/9CL/v1ZRcc8a//+/UK7du0EMzMzwcjISGjQoIEQEBAg7k9ISCj2l+eBAweE9u3bC9WqVRPMzMyEvn37CpcuXSr2elevXhV8fHwEMzMzwdTUVBgxYkSJfskW/WIKCQkRVCqV8ODBA3FfdHS0AEDYvn27JDFITU0VJk2aJDRu3FgwMjISTExMhB49egixsbFin6Jfis9vRffZqVMnoVGjRsLp06eFDh06CIaGhsL48ePFfZ06dRLPNXz4cEGlUknuv1u3boK5ublw+/btl95nx44dhc6dO0vaGzRoIFSvXl2SMLzI48ePBUtLS8HZ2VnIz89/Zf+i7+DXX38VLCwshD59+qjtf1Fi8McffwgAhDNnzpQoLqI3DccYkMZ27dqFOnXqSMqyL/Lxxx9j5syZaNGiBRYvXoxOnTohKCgIgwcPlvS9du0aBg4ciHfeeQcLFy6EhYUFRowYgbi4OADAgAEDsHjxYgDAkCFDsG7dOixZsqRU8cfFxeHdd99FTk4O5syZg4ULF6Jv376vHAD3999/o3v37khJScGsWbPg7++PEydOoF27dvj3338l/QcNGoRHjx4hKCgIgwYNQkhICGbPnl3iOAcMGACFQoHff/9dbNu4cSOcnZ3RokULSf8bN24gLCwM7777LhYtWoQpU6bgwoUL6NSpE+7cuQMAcHFxEUvho0ePxrp167Bu3Tp07NhRPE9qaip69uyJ5s2bY8mSJejSpUux8S1duhQ1atSAj48PCgoKAAA//vgj9u/fj+XLl8Pe3v6F95aXl4dTp05J7uPKlSu4cuUK+vfvL3nO/yLHjh1DWloahg4dCh0dnRIdAwCmpqaYOHEidu3ahTNnzryyf8uWLQHgtR8oSaQxuTMTejM9fPhQACD069evRP1jY2MFAMLHH3+s1j558mQBgHDw4EGxzdHRUQAgREREiG0pKSmCSqUSJk2aJLYV/W3++TJ6SSsGixcvFgAI9+7de2HcxVUMmjdvLlhbWwupqali27lz5wSlUikMHz5ccr2PPvpI7ZzvvfeeYGVl9cJrPnsfRX9jHThwoNC1a1dBEAShoKBAsLW1FWbPnl3sd5CdnS0UFBRI7kOlUglz5swR2172KKFTp04CAGHVqlXF7nu2YiAIgrBv3z4BgPD111+Lj5iKe/zxvGvXrgkAhOXLl6u1F/2t/PlHUYWFhcK9e/fUtry8PEEQBGHp0qUCAGHHjh2vvK4g/P+KwdatW4X09HTBwsJC6Nu3r7j/RRUDQRAEfX19YcyYMSW6DtGbhhUD0khGRgYAwMTEpET99+zZAwDw9/dXa580aRKAp4MYn+Xq6ooOHTqIn2vUqIGGDRvixo0bGsf8PHNzcwDAH3/8gcLCwhIdc/fuXcTGxmLEiBGwtLQU25s2bYp33nlHvM9nffrpp2qfO3TogNTUVPE7LImhQ4fi8OHDSEpKwsGDB5GUlIShQ4cW21elUkGpfPpHu6CgAKmpqTA2NkbDhg1L9DfiZ88zcuTIEvXt1q0bPvnkE8yZMwcDBgyAgYEBfvzxx1cel5qaCgCwsLBQay/6bp6vFjx8+BA1atRQ24pmVZT2Z/JZZmZmmDBhAnbu3ImzZ8++sr+FhQXu379f6usQvQmYGJBGTE1NAQCPHj0qUf+bN29CqVSiXr16au22trYwNzfHzZs31dodHBwk57CwsMCDBw80jFjqgw8+QLt27fDxxx/DxsYGgwcPxm+//fbSJKEozoYNG0r2ubi44P79+8jKylJrf/5ein4JluZeevXqBRMTE2zZsgUbNmxA69atJd9lkcLCQixevBj169eHSqVC9erVUaNGDZw/fx4PHz4s8TWLpgeW1IIFC2BpaYnY2FgsW7YM1tbWJT5WEAS1z0W/3DMzM9XajY2NER4ejvDwcEyZMkVtX2l/Jp83fvx4mJubY9asWSWKV6FQaHQdotcdEwPSiKmpKezt7XHx4sVSHVfS/5m+6Bnx879ASnONouffRQwNDREREYG///4bw4YNw/nz5/HBBx/gnXfekfQti7LcSxGVSoUBAwYgNDQUO3bseGG1AADmzZsHf39/dOzYEevXr8e+ffsQHh6ORo0albgyAjz9fkrj7NmzSElJAQBcuHChRMdYWVkBkCZJzs7OACD5+dLV1YWnpyc8PT3h6upa7DElvfbzSlM1SE9PR/Xq1TW6DtHrjokBaezdd9/F9evXERkZ+cq+jo6OKCwsxNWrV9Xak5OTkZ6eDkdHx3KLy8LCAunp6ZL256sSAKBUKtG1a1csWrQIly5dwjfffIODBw/i0KFDxZ67KM74+HjJvn/++QfVq1eHkZFR2W7gBYYOHYqzZ8/i0aNHxQ7YLLJt2zZ06dIFv/76KwYPHoxu3brB09NT8p2U5994s7KyMHLkSLi6umL06NEIDg7GqVOnXnmcg4MDDA0NkZCQoNbesGFD1K9fH2FhYZIKzIu0b98eFhYW2LRpk8aJ3YQJE2Bubv7SwaG3b99Gbm4uXFxcNLoG0euOiQFpbOrUqTAyMsLHH39c7Ap0169fx9KlSwE8LYUDkMwcWLRoEQCgd+/e5RZX3bp18fDhQ5w/f15sK1rg5llpaWmSY4sW+snJySn23HZ2dmjevDlCQ0PVftFevHgR+/fvF++zInTp0gVz587F999/D1tb2xf209HRkVQjtm7ditu3b6u1FSUwxSVRpTVt2jQkJiYiNDQUixYtQu3ateHj4/PC77GInp4eWrVqhdOnT0v2zZo1C/fv38eoUaOQl5cn2f/8PVarVg3Tpk3D5cuXMW3atGIrMuvXr0d0dPQL4ymqGvzxxx8vXBGyaJXEks7GIXrTcOVD0ljdunWxceNGfPDBB3BxcVFb+fDEiRPYunUrRowYAQBo1qwZfHx88NNPPyE9PR2dOnVCdHQ0QkND0b9//xdOhdPE4MGDMW3aNLz33nsYN24cHj9+jJUrV6JBgwZqg+/mzJmDiIgI9O7dG46OjkhJScEPP/yAt956C+3bt3/h+b/77jv07NkTHh4e8PX1xZMnT7B8+XKYmZmV6Pm0ppRKJaZPn/7Kfu+++y7mzJmDkSNHom3btrhw4QI2bNiAOnXqqPWrW7cuzM3NsWrVKpiYmMDIyAju7u5wcnIqVVwHDx7EDz/8gMDAQHHa4Zo1a9C5c2fMmDEDwcHBLz2+X79++Oqrr5CRkSGOEwCeVkguXryIoKAgREdHY/DgwXByckJWVhYuXryITZs2wcTERG3gYtFqmwsXLsShQ4cwcOBA2NraIikpCWFhYYiOjsaJEydeGs/48eOxePFinDt3rtjqT3h4OBwcHODm5laar4nozSHjjAiqIq5cuSKMGjVKqF27tqCvry+YmJgI7dq1E5YvX662eFFeXp4we/ZswcnJSdDT0xNq1ar10gWOnvf8NLkXTVcUhKcLFzVu3FjQ19cXGjZsKKxfv14yXfHAgQNCv379BHt7e0FfX1+wt7cXhgwZIly5ckVyjeen9P39999Cu3btBENDQ8HU1FTo06fPCxc4en465Jo1awQAQkJCwgu/U0F4+XS5l30H2dnZwqRJkwQ7OzvB0NBQaNeunRAZGVnsNMM//vhDcHV1FXR1dYtd4Kg4z54nIyNDcHR0FFq0aCFOGywyceJEQalUCpGRkS+9h+TkZEFXV1dYt25dsfsPHz4sDBw4ULCzsxP09PQEU1NToVWrVkJgYKBw9+7dYo/Ztm2b0K1bN8HS0lLQ1dUV7OzshA8++EA4fPiw2OfZ6YrPK/pv9/z3X1BQINjZ2QnTp09/6T0RvckUglCKEVBERBXA19cXV65cwdGjR+UO5aXCwsIwdOhQXL9+HXZ2dnKHQ1QhmBgQkewSExPRoEEDHDhwoNg3LL4uPDw80KFDh1c+HiF6kzExICIiIhFnJRAREZGIiQERERGJmBgQERGRiIkBERERiZgYEBERkahKrnyYnS93BEQVz6K1n9whEFW4J2e/r9DzG7pp/ueoomOTS5VMDIiIiEpEwcL585gYEBGR9irHt4xWFUwMiIhIe7FiIMFvhIiIiESsGBARkfbiowQJJgZERKS9+ChBgokBERFpL1YMJJgYEBGR9mLFQIKJARERaS9WDCSYKhEREZGIFQMiItJefJQgwcSAiIi0Fx8lSDAxICIi7cWKgQQTAyIi0l6sGEgwMSAiIu3FioEEvxEiIqIKFhERgT59+sDe3h4KhQJhYWEv7Pvpp59CoVBgyZIlau1paWnw9vaGqakpzM3N4evri8zMTLU+58+fR4cOHWBgYIBatWohODi41LEyMSAiIu2lUGq+lUJWVhaaNWuGFStWvLTfjh07cPLkSdjb20v2eXt7Iy4uDuHh4di9ezciIiIwevRocX9GRga6desGR0dHxMTE4LvvvsOsWbPw008/lSpWPkogIiLtpdR8jEFOTg5ycnLU2lQqFVQqlaRvz5490bNnz5ee7/bt2/j888+xb98+9O7dW23f5cuXsXfvXpw6dQqtWrUCACxfvhy9evXCggULYG9vjw0bNiA3NxerV6+Gvr4+GjVqhNjYWCxatEgtgXgVVgyIiEh7laFiEBQUBDMzM7UtKChIozAKCwsxbNgwTJkyBY0aNZLsj4yMhLm5uZgUAICnpyeUSiWioqLEPh07doS+vr7Yp3v37oiPj8eDBw9KHAsrBkREpL3KMCshICAA/v7+am3FVQtKYv78+dDV1cW4ceOK3Z+UlARra2u1Nl1dXVhaWiIpKUns4+TkpNbHxsZG3GdhYVGiWJgYEBGR9irDrIQXPTYorZiYGCxduhRnzpyB4jWYPslHCURERDI6evQoUlJS4ODgAF1dXejq6uLmzZuYNGkSateuDQCwtbVFSkqK2nH5+flIS0uDra2t2Cc5OVmtT9Hnoj4lwcSAiIi0l0Kh+VZOhg0bhvPnzyM2Nlbc7O3tMWXKFOzbtw8A4OHhgfT0dMTExIjHHTx4EIWFhXB3dxf7REREIC8vT+wTHh6Ohg0blvgxAsBHCUREpM0qaYGjzMxMXLt2TfyckJCA2NhYWFpawsHBAVZWVmr99fT0YGtri4YNGwIAXFxc0KNHD4waNQqrVq1CXl4e/Pz8MHjwYHFq49ChQzF79mz4+vpi2rRpuHjxIpYuXYrFixeXKlYmBkREpL0q6Zn+6dOn0aVLF/Fz0aBFHx8fhISElOgcGzZsgJ+fH7p27QqlUgkvLy8sW7ZM3G9mZob9+/dj7NixaNmyJapXr46ZM2eWaqoiACgEQRBKdcQbIDtf7giIKp5Faz+5QyCqcE/Ofl+h5zfssUjjY5/s9X91pzcQKwZERKS9XoNZAK8bDj4kIiIiESsGRESkvfh2RQkmBkREpL34KEGCiQEREWkvVgwkmBgQEZH2YmIgwcSAiIi0Fx8lSDBVIiIiIhErBkREpL34KEGCiQEREWkvPkqQYGJARETaixUDCSYGRESkvVgxkGBiQEREWkvBxECCNRQiIiISsWJARERaixUDKSYGRESkvZgXSDAxICIircWKgRQTAyIi0lpMDKSYGBARkdZiYiDFWQlEREQkYsWAiIi0FisGUkwMiIhIezEvkGBiQEREWosVAykmBkREpLWYGEgxMSAiIq3FxECKsxKIiIhIxIoBERFpLVYMpJgYEBGR9mJeIMHEgIiItBYrBlJMDIiISGsxMZDi4EMiItJaCoVC4600IiIi0KdPH9jb20OhUCAsLEzcl5eXh2nTpqFJkyYwMjKCvb09hg8fjjt37qidIy0tDd7e3jA1NYW5uTl8fX2RmZmp1uf8+fPo0KEDDAwMUKtWLQQHB5f6O2FiQEREVMGysrLQrFkzrFixQrLv8ePHOHPmDGbMmIEzZ87g999/R3x8PPr27avWz9vbG3FxcQgPD8fu3bsRERGB0aNHi/szMjLQrVs3ODo6IiYmBt999x1mzZqFn376qVSxKgRBEDS7zddXdr7cERBVPIvWfnKHQFThnpz9vkLPb+37m8bHpvw6SKPjFAoFduzYgf79+7+wz6lTp/C///0PN2/ehIODAy5fvgxXV1ecOnUKrVq1AgDs3bsXvXr1wn///Qd7e3usXLkSX331FZKSkqCvrw8A+OKLLxAWFoZ//vmnxPGxYkBERFqrLI8ScnJykJGRobbl5OSUS1wPHz6EQqGAubk5ACAyMhLm5uZiUgAAnp6eUCqViIqKEvt07NhRTAoAoHv37oiPj8eDBw9KfG0mBkREpLXKkhgEBQXBzMxMbQsKCipzTNnZ2Zg2bRqGDBkCU1NTAEBSUhKsra3V+unq6sLS0hJJSUliHxsbG7U+RZ+L+pQEZyUQEZHWKsushICAAPj7+6u1qVSqMsWTl5eHQYMGQRAErFy5skzn0hQTAyIi0lplSQxUKlWZE4FnFSUFN2/exMGDB8VqAQDY2toiJSVFrX9+fj7S0tJga2sr9klOTlbrU/S5qE9JvDaPEnJzcxEfH4/8fI4cJCIi7VKUFFy9ehV///03rKys1PZ7eHggPT0dMTExYtvBgwdRWFgId3d3sU9ERATy8vLEPuHh4WjYsCEsLCxKHIvsicHjx4/h6+uLatWqoVGjRkhMTAQAfP755/j2229ljo6IiKo0RRm2UsjMzERsbCxiY2MBAAkJCYiNjUViYiLy8vIwcOBAnD59Ghs2bEBBQQGSkpKQlJSE3NxcAICLiwt69OiBUaNGITo6GsePH4efnx8GDx4Me3t7AMDQoUOhr68PX19fxMXFYcuWLVi6dKnkcceryJ4YBAQE4Ny5czh8+DAMDAzEdk9PT2zZskXGyIiIqKqrrAWOTp8+DTc3N7i5uQEA/P394ebmhpkzZ+L27dvYuXMn/vvvPzRv3hx2dnbiduLECfEcGzZsgLOzM7p27YpevXqhffv2amsUmJmZYf/+/UhISEDLli0xadIkzJw5U22tg5KQfYxBWFgYtmzZgjZt2qh90Y0aNcL169dljIyIiKq6yloSuXPnznjZskElWVLI0tISGzdufGmfpk2b4ujRo6WO71myJwb37t2TTMEAnq4SxTWsiYioIvH3jJTsjxJatWqFP//8U/xc9B/pl19+gYeHh1xhERERaSXZKwbz5s1Dz549cenSJeTn52Pp0qW4dOkSTpw4gSNHjsgdHhERVWUsGEjIXjFo3749YmNjkZ+fjyZNmmD//v2wtrZGZGQkWrZsKXd4VAKbN25Az3feRmu3JvAe/D4unD8vd0hExWrXoi62LfkEN/Z/gydnv0efzk1f2HfZV4Px5Oz38BvaWa29ufNb2L3SD3cjgvHfofn4fvoQGBnqS47/sI87orcE4MHJxbh5IAiLv9BsXX2qWJU1+PBNIkti4O/vj6ysLABPX0Xp6OiIn3/+GdHR0bh06RLWr1+PJk2ayBEaldLev/ZgQXAQPvlsLDZv3YGGDZ0x5hNfpKamyh0akYSRoQoXrtzGhKCXz3jq26Up/tekNu6kpKu129Uww5+rPsf1W/fQcdgC9Bu7Aq51bfHznGFq/cZ9+DZm+/XBwjXhaDHwG/T+dDn+jrxc3rdD5YCJgZQsicHy5cvFd0h36dIFaWlpcoRB5WBd6BoMGDgI/d/zQt169TA9cDYMDAwQ9vt2uUMjkth//BJm/7AbOw+9uKplX8MMi6a9j5FfhiAvv0BtX88OjZGXX4AJQb/h6s0UxFxKxOffbMF7nm6oU6s6AMDcxBCBn70L3xlrsWXvaST8dx8Xr97Bn0cuVOi9kWaYGEjJMsagdu3aWLZsGbp16wZBEBAZGfnCVZk6duxYydFRSeXl5uLypTj4jvpEbFMqlWjTpi3OnzsrY2REmlEoFPj16+FYHHoAl29IXzqj0tdFXl6B2tSyJzlPF6Bp27wubty6j65tnKFUKmBvbY6z26fDxEiFk+cS8MWi3/Ffcnpl3QqVUFX+Ba8pWRKD7777Dp9++imCgoKgUCjw3nvvFdtPoVCgoKCg2H0kvwfpD1BQUCBZutPKygoJCTdkiopIc5NGvoP8gkKs2HS42P2Ho+Mx338AJg7viu83HoaRoT6+HtcPAGBbwwwA4PRWdSiVCkz9qBsmf7cdGZlPEDj2Xexe6YfWg4IkVQii140sjxL69++PpKQkZGRkQBAE8V3Rz28lecRQke/DJiLt4eZSC2OHdMbowPUv7HP5RhJGzVyHccO6Ii1yEf79ex7+vZ2KpPsZEAoLATz9C42+ni4mBW/D35GXEX3hX/gEhKCegzU6tW5QWbdDJVVJSyK/SWSdrmhsbIxDhw7ByckJurqahRIUFITZs2ertX01IxDTZ84qhwjpZSzMLaCjoyMZaJiamorq1avLFBWRZtq51YW1pTGu7Jkjtunq6uBb/wHw8+4C596BAIAte09jy97TsLY0QdaTHAjC08GGCf89/XOQdD8DAPDPM48i7j/IxP30TNSyLfmLbKhy8FGClOzrGHTq1En89+zsbPGFEUWefe1kcYp7H7agU36vwaQX09PXh4trI0SdjMTbXT0BAIWFhYiKisTgIR/KHB1R6Wz88xQORsWrte36YSw2/hmNtX+clPRPSXsEABjerw2yc/Nw4OQ/AIDI2KeP0erXtsbt/5vVYGFaDdXNjZF4lwOtXzdMDKRkTwweP36MqVOn4rfffit2iturxhgU9z7sbL65udIM8xmJGV9OQ6NGjdG4SVOsXxeKJ0+eoP97A+QOjUjCyFAfdWvVED/XrmmFpg1q4kHGY9xKeoC0h1lq/fPyC5B8PwNXb6aIbZ9+0BEnz91A5uNcdG3jjHkT+mPG8j/wMPMJAOBaYgp2HTqHBVMGwu/rTcjIzMacz/si/t9kHDl9pXJulEqMeYGU7InBlClTcOjQIaxcuRLDhg3DihUrcPv2bfz444987fIboEfPXniQloYfvl+G+/fvoaGzC3748RdY8VECvYZauDpi/y/jxc/Bk70AAOt2nnzp2IJntWrsiOmf9oZxNX3E/5sMv282YdOfp9T6+M5Yh+DJA/D7sjEoLBRwLOYq+o1dgfz8wvK7GSoXrBhIKYSSvNKpAjk4OGDt2rXo3LkzTE1NcebMGdSrVw/r1q3Dpk2bsGfPnlKfkxUD0gYWrf3kDoGowj05+32Fnr/+lL0aH3v1ux7lGMnrQ/YlkdPS0lCnTh0AT8cTFM1EaN++PSIiIuQMjYiIqjiFQvOtqpI9MahTpw4SEhIAAM7Ozvjtt98AALt27YK5ubmMkRERUVXHlQ+lZE8MRo4ciXPnzgEAvvjiC6xYsQIGBgaYOHEipkyZInN0RERUlbFiICX74MOJEyeK/+7p6Yl//vkHMTExqFevHpo2ffGbz4iIiMpKqazCv+E1JFvFIDIyErt371ZrKxqE+Omnn+L777/nCoZERFShWDGQki0xmDNnDuLi4sTPFy5cgK+vLzw9PREQEIBdu3YhKChIrvCIiIi0kmyJQWxsLLp27Sp+3rx5M9zd3fHzzz9j4sSJWLZsmTgQkYiIqCJw8KGUbGMMHjx4ABsbG/HzkSNH0LNnT/Fz69atcevWLTlCIyIiLVGFf79rTLaKgY2NjThNMTc3F2fOnEGbNm3E/Y8ePYKenp5c4RERkRZgxUBKtsSgV69e+OKLL3D06FEEBASgWrVq6NChg7j//PnzqFu3rlzhERGRFmBiICXbo4S5c+diwIAB6NSpE4yNjREaGgp9fX1x/+rVq9GtWze5wiMiIi1QhX+/a0y2xKB69eqIiIjAw4cPYWxsDB0dHbX9W7duhbGxsUzRERERaSfZFzgyMzMrtt3S0rKSIyEiIm1TlR8JaEr2xICIiEguzAukmBgQEZHWYsVAiokBERFpLeYFUrK/XZGIiEgulTVdMSIiAn369IG9vT0UCgXCwsLU9guCgJkzZ8LOzg6Ghobw9PTE1atX1fqkpaXB29sbpqamMDc3h6+vLzIzM9X6nD9/Hh06dICBgQFq1aqF4ODgUn8nTAyIiIgqWFZWFpo1a4YVK1YUuz84OBjLli3DqlWrEBUVBSMjI3Tv3h3Z2dliH29vb8TFxSE8PBy7d+9GREQERo8eLe7PyMhAt27d4OjoiJiYGHz33XeYNWsWfvrpp1LFykcJRESktSrrUULPnj3Vlv1/liAIWLJkCaZPn45+/foBePq2YRsbG4SFhWHw4MG4fPky9u7di1OnTqFVq1YAgOXLl6NXr15YsGAB7O3tsWHDBuTm5mL16tXQ19dHo0aNEBsbi0WLFqklEK/CigEREWmtsjxKyMnJQUZGhtqWk5NT6hgSEhKQlJQET09Psc3MzAzu7u6IjIwEAERGRsLc3FxMCgDA09MTSqUSUVFRYp+OHTuqLRbYvXt3xMfH48GDByWOh4kBERFpLYVC8y0oKAhmZmZqW1BQUKljSEpKAgC1FwsWfS7al5SUBGtra7X9urq6sLS0VOtT3DmevUZJ8FECERFprbJMVwwICIC/v79am0qlKmtIsmNiQEREWqssYwxUKlW5JAK2trYAgOTkZNjZ2YntycnJaN68udgnJSVF7bj8/HykpaWJx9va2iI5OVmtT9Hnoj4lwUcJREREMnJycoKtrS0OHDggtmVkZCAqKgoeHh4AAA8PD6SnpyMmJkbsc/DgQRQWFsLd3V3sExERgby8PLFPeHg4GjZsCAsLixLHw8SAiIi0VmWtY5CZmYnY2FjExsYCeDrgMDY2FomJiVAoFJgwYQK+/vpr7Ny5ExcuXMDw4cNhb2+P/v37AwBcXFzQo0cPjBo1CtHR0Th+/Dj8/PwwePBg2NvbAwCGDh0KfX19+Pr6Ii4uDlu2bMHSpUsljztehY8SiIhIa1XWdMXTp0+jS5cu4ueiX9Y+Pj4ICQnB1KlTkZWVhdGjRyM9PR3t27fH3r17YWBgIB6zYcMG+Pn5oWvXrlAqlfDy8sKyZcvE/WZmZti/fz/Gjh2Lli1bonr16pg5c2appioCgEIQBKGM9/vayc6XOwKiimfR2k/uEIgq3JOz31fo+TssPKbxsUcntS/HSF4frBgQEZHW4kuUpJgYEBGR1mJeIMXBh0RERCRixYCIiLQWHyVIMTEgIiKtxbxAiokBERFpLVYMpJgYEBGR1mJeIMXEgIiItJaSmYEEZyUQERGRiBUDIiLSWiwYSDExICIircXBh1JMDIiISGspmRdIMDEgIiKtxYqBFBMDIiLSWswLpDgrgYiIiESsGBARkdZSgCWD5zExICIircXBh1JMDIiISGtx8KEUEwMiItJazAukmBgQEZHW4rsSpDgrgYiIiESsGBARkdZiwUCKiQEREWktDj6UYmJARERai3mBFBMDIiLSWhx8KMXEgIiItBbTAqkSJQY7d+4s8Qn79u2rcTBEREQkrxIlBv379y/RyRQKBQoKCsoSDxERUaXh4EOpEiUGhYWFFR0HERFRpeO7EqQ4xoCIiLQWKwZSGq18mJWVhT179mDVqlVYtmyZ2kZERPSmUCg030qjoKAAM2bMgJOTEwwNDVG3bl3MnTsXgiCIfQRBwMyZM2FnZwdDQ0N4enri6tWraudJS0uDt7c3TE1NYW5uDl9fX2RmZpbHVyEqdcXg7Nmz6NWrFx4/foysrCxYWlri/v37qFatGqytrTFu3LhyDZCIiKiiVFbFYP78+Vi5ciVCQ0PRqFEjnD59GiNHjoSZmZn4ezM4OBjLli1DaGgonJycMGPGDHTv3h2XLl2CgYEBAMDb2xt3795FeHg48vLyMHLkSIwePRobN24st1hLXTGYOHEi+vTpgwcPHsDQ0BAnT57EzZs30bJlSyxYsKDcAiMiIqoqTpw4gX79+qF3796oXbs2Bg4ciG7duiE6OhrA02rBkiVLMH36dPTr1w9NmzbF2rVrcefOHYSFhQEALl++jL179+KXX36Bu7s72rdvj+XLl2Pz5s24c+dOucVa6sQgNjYWkyZNglKphI6ODnJyclCrVi0EBwfjyy+/LLfAiIiIKppSofmWk5ODjIwMtS0nJ6fY67Rt2xYHDhzAlStXAADnzp3DsWPH0LNnTwBAQkICkpKS4OnpKR5jZmYGd3d3REZGAgAiIyNhbm6OVq1aiX08PT2hVCoRFRVVft9JaQ/Q09ODUvn0MGtrayQmJgJ4egO3bt0qt8CIiIgqmkKh0HgLCgqCmZmZ2hYUFFTsdb744gsMHjwYzs7O0NPTg5ubGyZMmABvb28AQFJSEgDAxsZG7TgbGxtxX1JSEqytrdX26+rqwtLSUuxTHko9xsDNzQ2nTp1C/fr10alTJ8ycORP379/HunXr0Lhx43ILjIiIqKKVZYRBQEAA/P391dpUKlWxfX/77Tds2LABGzduRKNGjRAbG4sJEybA3t4ePj4+ZYii/JU6MZg3bx4ePXoEAPjmm28wfPhwjBkzBvXr18fq1avLPUAiIqKKUpZ3JahUqhcmAs+bMmWKWDUAgCZNmuDmzZsICgqCj48PbG1tAQDJycmws7MTj0tOTkbz5s0BALa2tkhJSVE7b35+PtLS0sTjy0OpE4Nnn21YW1tj79695RYMERFRVfT48WPxMXwRHR0dcQFBJycn2Nra4sCBA2IikJGRgaioKIwZMwYA4OHhgfT0dMTExKBly5YAgIMHD6KwsBDu7u7lFisXOCIiIq1VWesb9enTB9988w0cHBzQqFEjnD17FosWLcJHH330f3EoMGHCBHz99deoX7++OF3R3t5efC2Bi4sLevTogVGjRmHVqlXIy8uDn58fBg8eDHt7+3KLtdSJgZOT00vnfd64caNMAREREVWWylrHYPny5ZgxYwY+++wzpKSkwN7eHp988glmzpwp9pk6dSqysrIwevRopKeno3379ti7d6+4hgEAbNiwAX5+fujatSuUSiW8vLzKfXFBhfDsskslsHTpUrXPeXl5OHv2LPbu3Ss+Q5Fbdr7cERBVPIvWfnKHQFThnpz9vkLP/8m2OI2P/XFgo3KM5PVR6orB+PHji21fsWIFTp8+XeaAiIiIKktZBh9WVRq9K6E4PXv2xPbt28vrdERERBWust6V8CYpt8Rg27ZtsLS0LK/TERERkQw0WuDo2cEagiAgKSkJ9+7dww8//FCuwREREVUkvnZZqtSJQb9+/dS+SKVSiRo1aqBz585wdnYu1+CI6MWqNWkndwhEb7xyK5tXIaVODGbNmlUBYRAREVU+VgykSp0s6ejoSJZkBIDU1FTo6OiUS1BERESVoSxvV6yqSl0xeNGyBzk5OdDX1y9zQERERJWlKv+C11SJE4OilZUUCgV++eUXGBsbi/sKCgoQERHBMQZERERvuBInBosXLwbwtGKwatUqtccG+vr6qF27NlatWlX+ERIREVUQjjGQKnFikJCQAADo0qULfv/9d1hYWFRYUERERJWBjxKkSj3G4NChQxURBxERUaVjwUCq1LMSvLy8MH/+fEl7cHAw3n///XIJioiIqDIoFQqNt6qq1IlBREQEevXqJWnv2bMnIiIiyiUoIiKiyqAsw1ZVlfreMjMzi52WqKenh4yMjHIJioiIiORR6sSgSZMm2LJli6R98+bNcHV1LZegiIiIKgPfrihV6sGHM2bMwIABA3D9+nW8/fbbAIADBw5g48aN2LZtW7kHSEREVFGq8lgBTZU6MejTpw/CwsIwb948bNu2DYaGhmjWrBkOHjzI1y4TEdEbhXmBVKkTAwDo3bs3evfuDQDIyMjApk2bMHnyZMTExKCgoKBcAyQiIqooXMdASuOBlREREfDx8YG9vT0WLlyIt99+GydPnizP2IiIiCoUpytKlapikJSUhJCQEPz666/IyMjAoEGDkJOTg7CwMA48JCIiqgJKXDHo06cPGjZsiPPnz2PJkiW4c+cOli9fXpGxERERVSjOSpAqccXgr7/+wrhx4zBmzBjUr1+/ImMiIiKqFBxjIFXiisGxY8fw6NEjtGzZEu7u7vj+++9x//79ioyNiIioQinK8E9VVeLEoE2bNvj5559x9+5dfPLJJ9i8eTPs7e1RWFiI8PBwPHr0qCLjJCIiKndKheZbVVXqWQlGRkb46KOPcOzYMVy4cAGTJk3Ct99+C2tra/Tt27ciYiQiIqoQTAykyvQeiIYNGyI4OBj//fcfNm3aVF4xERERkUw0WuDoeTo6Oujfvz/69+9fHqcjIiKqFIqqPL1AQ+WSGBAREb2JqvIjAU0xMSAiIq3FgoFUmcYYEBERvckqc0nk27dv48MPP4SVlRUMDQ3RpEkTnD59WtwvCAJmzpwJOzs7GBoawtPTE1evXlU7R1paGry9vWFqagpzc3P4+voiMzOzzN/Ds5gYEBGR1qqsWQkPHjxAu3btoKenh7/++guXLl3CwoULYWFhIfYJDg7GsmXLsGrVKkRFRcHIyAjdu3dHdna22Mfb2xtxcXEIDw/H7t27ERERgdGjR5fX1wEAUAiCIJTrGV8D2flyR0BU8Wp+xJlAVPWlrh1SoedfdixB42PHtXcqcd8vvvgCx48fx9GjR4vdLwgC7O3tMWnSJEyePBkA8PDhQ9jY2CAkJASDBw/G5cuX4erqilOnTqFVq1YAgL1796JXr17477//YG9vr/G9PIsVAyIi0lpleVdCTk4OMjIy1LacnJxir7Nz5060atUK77//PqytreHm5oaff/5Z3J+QkICkpCR4enqKbWZmZnB3d0dkZCQAIDIyEubm5mJSAACenp5QKpWIiooqt++EiQEREWktJRQab0FBQTAzM1PbgoKCir3OjRs3sHLlStSvXx/79u3DmDFjMG7cOISGhgJ4+vZiALCxsVE7zsbGRtyXlJQEa2trtf26urqwtLQU+5QHzkogIiKtVZZZCQEBAfD391drU6lUxfYtLCxEq1atMG/ePACAm5sbLl68iFWrVsHHx0fzICoAKwZERKS1yjL4UKVSwdTUVG17UWJgZ2cHV1dXtTYXFxckJiYCAGxtbQEAycnJan2Sk5PFfba2tkhJSVHbn5+fj7S0NLFPeWBiQEREWquypiu2a9cO8fHxam1XrlyBo6MjAMDJyQm2trY4cOCAuD8jIwNRUVHw8PAAAHh4eCA9PR0xMTFin4MHD6KwsBDu7u6afgUSfJRARERUwSZOnIi2bdti3rx5GDRoEKKjo/HTTz/hp59+AvB0aeYJEybg66+/Rv369eHk5IQZM2bA3t5efN2Ai4sLevTogVGjRmHVqlXIy8uDn58fBg8eXG4zEgAmBkREpMUqa+XD1q1bY8eOHQgICMCcOXPg5OSEJUuWwNvbW+wzdepUZGVlYfTo0UhPT0f79u2xd+9eGBgYiH02bNgAPz8/dO3aFUqlEl5eXli2bFm5xsp1DIjeUFzHgLRBRa9j8Gt0osbH+v7PoRwjeX2wYkBERFqL70qQYmJARERaiyPwpZgYEBGR1lKwZCDBZImIiIhErBgQEZHWYr1A6rWpGFy7dg379u3DkydPADx90xQREVFFqqwFjt4ksicGqamp8PT0RIMGDdCrVy/cvXsXAODr64tJkybJHB0REVVlijJsVZXsicHEiROhq6uLxMREVKtWTWz/4IMPsHfvXhkjIyKiqq4sr12uqmQfY7B//37s27cPb731llp7/fr1cfPmTZmiIiIibcBZCVKyVwyysrLUKgVF0tLSXviWKiIiIqoYsicGHTp0wNq1a8XPCoUChYWFCA4ORpcuXWSMjIiIqjplGbaqSvZHCcHBwejatStOnz6N3NxcTJ06FXFxcUhLS8Px48flDo+IiKowPkqQkj3pady4Ma5cuYL27dujX79+yMrKwoABA3D27FnUrVtX7vCIiKgK46wEKdkrBgBgZmaGr776Su4wiIhIy7BiICVLYnD+/PkS923atGkFRkJERNpM9rL5a0iWxKB58+ZQKBSvXN1QoVCgoKCgkqIiIiIiWRKDhIQEOS5LRESkho8SpGRJDBwdHeW4LBERkRqmBVKvxeDD+Ph4LF++HJcvXwYAuLi44PPPP0fDhg1ljoyIiKoyFgykZB93sX37djRu3BgxMTFo1qwZmjVrhjNnzqBx48bYvn273OEREVEVpoRC462qkr1iMHXqVAQEBGDOnDlq7YGBgZg6dSq8vLxkioyIiKo6VgykZK8Y3L17F8OHD5e0f/jhh+IrmImIiKhyyJ4YdO7cGUePHpW0Hzt2DB06dJAhIiIi0haKMvxTVcnyKGHnzp3iv/ft2xfTpk1DTEwM2rRpAwA4efIktm7ditmzZ8sRHhERaQk+SpBSCK9aZagCKJUlK1RousBRdn6pDyF649T8aJPcIRBVuNS1Qyr0/Hvj7ml8bI9GNcoxkteHLBWDwsJCOS5LRESkhhUDKdlnJRAREcmFiYHUa5EYZGVl4ciRI0hMTERubq7avnHjxskUFRERkfaRPTE4e/YsevXqhcePHyMrKwuWlpa4f/8+qlWrBmtrayYGRERUYary7AJNyT5dceLEiejTpw8ePHgAQ0NDnDx5Ejdv3kTLli2xYMECucMjIqIqTKnQfKuqZE8MYmNjMWnSJCiVSujo6CAnJwe1atVCcHAwvvzyS7nDIyKiKkyOdQy+/fZbKBQKTJgwQWzLzs7G2LFjYWVlBWNjY3h5eSE5OVntuMTERPTu3VusqE+ZMgX5+eU/DU/2xEBPT0+cvmhtbY3ExEQAgJmZGW7duiVnaEREVMUpFJpvmjh16hR+/PFHNG3aVK194sSJ2LVrF7Zu3YojR47gzp07GDBggLi/oKAAvXv3Rm5uLk6cOIHQ0FCEhIRg5syZZbn9YsmeGLi5ueHUqVMAgE6dOmHmzJnYsGEDJkyYgMaNG8scHRERUfnIzMyEt7c3fv75Z1hYWIjtDx8+xK+//opFixbh7bffRsuWLbFmzRqcOHECJ0+eBADs378fly5dwvr169G8eXP07NkTc+fOxYoVKySD9stK9sRg3rx5sLOzAwB88803sLCwwJgxY3Dv3j389NNPMkdHRERVWVkeJeTk5CAjI0Nty8nJeeG1xo4di969e8PT01OtPSYmBnl5eWrtzs7OcHBwQGRkJAAgMjISTZo0gY2Njdine/fuyMjIQFxcXLl+J7LOShAEAdbW1mJlwNraGnv37pUzJNLA5o0bELrmV9y/fw8NGjrjiy9noMlzZTKi14FHwxrw6+WC5rUtYGtRDcOWRGDPmdsAAF0dBb7yagrPZvZwtDbGo8e5OBKXjDm/nUNS+hPxHOsndEATRwtUNzFA+uNcRMQlYfYW9T4AMLanM4Z3qYtaVkZIe5SD1QeuYtGuS5V6v/RqZRlEGBQUJFm6PzAwELNmzZL03bx5M86cOSNWyJ+VlJQEfX19mJubq7Xb2NggKSlJ7PNsUlC0v2hfeZI9MahXrx7i4uJQv359OUMhDe39aw8WBAdheuBsNGnSDBvWhWLMJ774Y/deWFlZyR0ekZpqKl3EJT7AxogbWDte/SVthvq6aFrbEgv+uIi4xHSYG+lj3octsGFiB3QN3C/2O3Y5BUt2XUJS+hPYWVTDnCHNsebzdug592+xT9CHLdClsR0CN8Xi0q10WBjrw8JIVWn3SSVXlkGEAQEB8Pf3V2tTqaT/nW/duoXx48cjPDwcBgYGGl+vssiaGCiVStSvXx+pqalMDN5Q60LXYMDAQej/nhcAYHrgbEREHEbY79vhO2q0zNERqTtw/i4OnC/+de6PnuTBK/iQWtu0tTH4e3Z31LSqhtupjwEAq/bFi/v/S32MpbsvY934DtDVUSC/QEADe1OMfLs+2n+5B9eSHgEAEu9nVdAdUVmVZeVDlUpVbCLwvJiYGKSkpKBFixZiW0FBASIiIvD9999j3759yM3NRXp6ulrVIDk5Gba2tgAAW1tbREdHq523aNZCUZ/yIvsYg2+//RZTpkzBxYsX5Q6FSikvNxeXL8WhjUdbsU2pVKJNm7Y4f+6sjJERlQ/TanooLBSQkVX84C5zI30MbOuI6Gv3kV/w9H103ZvXxM17mejWvCbOLOyDswv7YMlH/4O5kX5lhk4lpCjDVlJdu3bFhQsXEBsbK26tWrWCt7e3+O96eno4cOCAeEx8fDwSExPh4eEBAPDw8MCFCxeQkpIi9gkPD4epqSlcXV01/wKKIfvKh8OHD8fjx4/RrFkz6Ovrw9DQUG1/WlqaTJHRqzxIf4CCggLJIwMrKyskJNyQKSqi8qHSU2LmoObYfvImHj33ytbAQc3g+04DGKl0cerafQxZdETc52hthLesjNDvf7Xw2Y8noaNU4GvvFgj5vD36f3uwsm+DXgMmJiaSWXZGRkawsrIS2319feHv7w9LS0uYmpri888/h4eHB9q0aQMA6NatG1xdXTFs2DAEBwcjKSkJ06dPx9ixY0tUtSgN2RODJUuWlOn4nJwcyShQQadk5R0iouLo6ijw69h2UCiAKSHSwWLL91zG+ogbqGVlhCnvNcYPo9tgyKIIAIBSoYCBvg4+++kkrv/fo4Txv0Th0NweqGdrIj5eoNeD8jV5i9LixYuhVCrh5eWFnJwcdO/eHT/88IO4X0dHB7t378aYMWPg4eEBIyMj+Pj4YM6cOeUei+yJgY+PT5mOL25U6FczAjF95qwynZdezcLcAjo6OkhNTVVrT01NRfXq1WWKiqhsdHUUWD22HWpVN0L/bw9KqgUAkJaZi7TMXFxPeoQrdx7iwtL+aFXPCqevpSI5/Qny8gvFpAAArtzJAAC8ZWXExOA1I1dacPjwYbXPBgYGWLFiBVasWPHCYxwdHbFnz54Kjuw1GGMAANevX8f06dMxZMgQ8fnJX3/9VaK5mQEBAXj48KHaNmVaQEWHTAD09PXh4toIUScjxbbCwkJERUWiaTM3GSMj0kxRUlDH1gQD5h/Cg8xXLxyj+L/5bipdHQBA1NX70NNVora1sdinrq0JAOBWKgchvnYqY5DBG0b2xODIkSNo0qQJoqKi8PvvvyMzMxMAcO7cOQQGBr7yeJVKBVNTU7WNjxEqzzCfkfh922/YGbYDN65fx9dzZuHJkyfo/96AVx5LVNmMVLpo7GCOxg7mAACHGsZo7GCOmlbVoKujQMjn7dHcyRKfrIyEjlIBazMDWJsZQE/n6f8qW9axwsee9dHYwRxvWVVDBxcb/DymLW4kP8Kpa/cBAEfikhCbkIZlH7ujiaMFmtW2wKKRrXHowl21KgK9HuR4V8LrTiEIgiBnAB4eHnj//ffh7+8PExMTnDt3DnXq1EF0dDQGDBiA//77r9TnLKbyRxVo04b14gJHDZ1dMO3L6WjatJncYVV5NT/aJHcIb5x2ztbY+WVXSfumozcwf8dFxC7qW+xxfecdwPF/UuDylhmCPmyJRg7mqKavi+SHT3Dw/F0s3BmHuw/+/wJHtuaG+HZYS3RpbIusnHwcOH8XMzadRfoLZjfQi6WuHVKh54++8VDjY/9Xx6wcI3l9yJ4YGBsb48KFC3ByclJLDP799184OzsjOzu71OdkYkDagIkBaQMmBpVP9kcJ5ubmuHtXuuDI2bNnUbNmTRkiIiIibcEhBlKyJwaDBw/GtGnTkJSUBIVCgcLCQhw/fhyTJ0/G8OHD5Q6PiIiqMmYGErInBvPmzYOzszNq1aqFzMxMuLq6omPHjmjbti2mT58ud3hERFSFcfChlOzrGOjr6+Pnn3/GjBkzcPHiRWRmZsLNzY3vTiAiogr3mqxv9FqRPTEo4uDgAAcHB7nDICIiLcK8QEr2xKCgoAAhISE4cOAAUlJSUFhYqLb/4EGuLU5ERFRZZE8Mxo8fj5CQEPTu3RuNGzeGgnUdIiKqLPyVIyF7YrB582b89ttv6NWrl9yhEBGRlqnKgwg1JXtioK+vj3r16skdBhERaSEWqaVkn644adIkLF26FDIvwEhERFqIyxhIyV4xOHbsGA4dOoS//voLjRo1gp6entr+33//XabIiIioyqvKv+E1JHtiYG5ujvfee0/uMIiIiAivQWKwZs0auUMgIiItxcGHUrInBkRERHLh4EMpWRIDNze3Eq9XcObMmQqOhoiItBXzAilZEoP+/fvLcVkiIiJ1zAwkZEkMAgMD5bgsERGRGo4xkJJ9HQMiIiJ6fcg++FCpVL50vEFBQUElRkNERNqEgw+lZE8MduzYofY5Ly8PZ8+eRWhoKGbPni1TVEREpA2YF0jJnhj069dP0jZw4EA0atQIW7Zsga+vrwxRERGRVmBmIPHajjFo06YNDhw4IHcYRERUhSnK8E9VJXvFoDhPnjzBsmXLULNmTblDISKiKoxjDKRkSwwuXryIxo0bw8LCQm3woSAIePToEapVq4b169fLFR4REZFWki0xaNq0KVq3bo358+cjOzsbZmZmAJ7OUqhRowbc3d1hYWEhV3hERKQFWDCQki0xOHLkCNasWYPJkyejsLAQXl5e8PX1RceOHeUKiYiItA0zAwnZBh926NABq1evxt27d7F8+XL8+++/6Ny5Mxo0aID58+cjKSlJrtCIiEhLcPChlOyzEoyMjDBy5EgcOXIEV65cwfvvv48VK1bAwcEBffv2lTs8IiKqwhQKzbfSCAoKQuvWrWFiYgJra2v0798f8fHxan2ys7MxduxYWFlZwdjYGF5eXkhOTlbrk5iYiN69e6NatWqwtrbGlClTkJ+fX9avQY3sicGz6tWrhy+//BLTp0+HiYkJ/vzzT7lDIiKiKkxRhq00jhw5grFjx+LkyZMIDw9HXl4eunXrhqysLLHPxIkTsWvXLmzduhVHjhzBnTt3MGDAAHF/QUEBevfujdzcXJw4cQKhoaEICQnBzJkzNb7/4igEQRDK9YwaioiIwOrVq7F9+3YolUoMGjQIvr6+aNOmTanPlV2+yRPRa6nmR5vkDoGowqWuHVKh57+e8kTjY+taG2p87L1792BtbY0jR46gY8eOePjwIWrUqIGNGzdi4MCBAIB//vkHLi4uiIyMRJs2bfDXX3/h3XffxZ07d2BjYwMAWLVqFaZNm4Z79+5BX19f43ieJWvF4M6dO5g3bx4aNGiAzp0749q1a1i2bBnu3LmDn3/+WaOkgIiIqMTKUDLIyclBRkaG2paTk1Oiyz58+BAAYGlpCQCIiYlBXl4ePD09xT7Ozs5wcHBAZGQkACAyMhJNmjQRkwIA6N69OzIyMhAXF6f5d/Ac2RKDnj17wtHREcuXL8d7772Hy5cv49ixYxg5ciSMjIzkCouIiLRIWQYfBgUFwczMTG0LCgp65TULCwsxYcIEtGvXDo0bNwYAJCUlQV9fH+bm5mp9bWxsxMH4SUlJaklB0f6ifeVFtumKenp62LZtG959913o6OjIFQYREWmxsqx8GBAQAH9/f7U2lUr1yuPGjh2Lixcv4tixY5pfvALJlhjs3LlTrksTEREBKNsyBiqVqkSJwLP8/Pywe/duRERE4K233hLbbW1tkZubi/T0dLWqQXJyMmxtbcU+0dHRaucrmrVQ1Kc8vFazEoiIiCpVJU1LEAQBfn5+2LFjBw4ePAgnJye1/S1btoSenp7aywPj4+ORmJgIDw8PAICHhwcuXLiAlJQUsU94eDhMTU3h6upauoBe4rV8iRIREVFVMnbsWGzcuBF//PEHTExMxDEBZmZmMDQ0hJmZGXx9feHv7w9LS0uYmpri888/h4eHhzgQv1u3bnB1dcWwYcMQHByMpKQkTJ8+HWPHji115eJlmBgQEZHWqqwVDFeuXAkA6Ny5s1r7mjVrMGLECADA4sWLoVQq4eXlhZycHHTv3h0//PCD2FdHRwe7d+/GmDFj4OHhASMjI/j4+GDOnDnlGutrs45BeeI6BqQNuI4BaYOKXscgMa1k0wuL42BZfn9Lf52wYkBERFqr6r7xQHNMDIiISGuVZbpiVcXEgIiItBgzg+dxuiIRERGJWDEgIiKtxUcJUkwMiIhIazEvkGJiQEREWosVAykmBkREpLUqa4GjNwkTAyIi0l7MCyQ4K4GIiIhErBgQEZHWYsFAiokBERFpLQ4+lGJiQEREWouDD6WYGBARkfZiXiDBxICIiLQW8wIpzkogIiIiESsGRESktTj4UIqJARERaS0OPpRiYkBERFqLFQMpjjEgIiIiESsGRESktVgxkGLFgIiIiESsGBARkdbi4EMpJgZERKS1+ChBiokBERFpLeYFUkwMiIhIezEzkODgQyIiIhKxYkBERFqLgw+lmBgQEZHW4uBDKSYGRESktZgXSHGMARERaS9FGTYNrFixArVr14aBgQHc3d0RHR1d1jsod0wMiIhIaynK8E9pbdmyBf7+/ggMDMSZM2fQrFkzdO/eHSkpKRVwZ5pjYkBERFQJFi1ahFGjRmHkyJFwdXXFqlWrUK1aNaxevVru0NQwMSAiIq2lUGi+5eTkICMjQ23Lyckp9jq5ubmIiYmBp6en2KZUKuHp6YnIyMjKut0SqZKDDw2q5F29vnJychAUFISAgACoVCq5w9EaqWuHyB2CVuHPedVUlt8Xs74OwuzZs9XaAgMDMWvWLEnf+/fvo6CgADY2NmrtNjY2+OeffzQPogIoBEEQ5A6C3mwZGRkwMzPDw4cPYWpqKnc4RBWCP+f0vJycHEmFQKVSFZs43rlzBzVr1sSJEyfg4eEhtk+dOhVHjhxBVFRUhcdbUvy7NRERkQZelAQUp3r16tDR0UFycrJae3JyMmxtbSsiPI1xjAEREVEF09fXR8uWLXHgwAGxrbCwEAcOHFCrILwOWDEgIiKqBP7+/vDx8UGrVq3wv//9D0uWLEFWVhZGjhwpd2hqmBhQmalUKgQGBnJAFlVp/Dmnsvrggw9w7949zJw5E0lJSWjevDn27t0rGZAoNw4+JCIiIhHHGBAREZGIiQERERGJmBgQERGRiIkBVYiwsDDUq1cPOjo6mDBhgtzhkJaaNWsWmjdvLncYIoVCgbCwsBfu//fff6FQKBAbG1tpMRE9j4kBSdy7dw9jxoyBg4MDVCoVbG1t0b17dxw/frzE5/jkk08wcOBA3Lp1C3Pnzq3AaKmq6tOnD3r06FHsvqNHj0KhUOD8+fOVHBVR1cfpiiTh5eWF3NxchIaGok6dOkhOTsaBAweQmppaouMzMzORkpKC7t27w97evoKjparK19cXXl5e+O+///DWW2+p7VuzZg1atWqFpk2byhTd/1dQUACFQgGlkn/PoqqBP8mkJj09HUePHsX8+fPRpUsXODo64n//+x8CAgLQt29fAE9fHdqkSRMYGRmhVq1a+Oyzz5CZmQkAOHz4MExMTAAAb7/9NhQKBQ4fPgwAOHbsGDp06ABDQ0PUqlUL48aNQ1ZWliz3Sa+/d999FzVq1EBISIhae2ZmJrZu3QpfX1+Ym5ur7QsLC4NCoXjhOUeMGIH+/ftjwYIFsLOzg5WVFcaOHYu8vDyxT05ODiZPnoyaNWvCyMgI7u7u4s8wAISEhMDc3Bw7d+6Eq6srVCoVEhMTcerUKbzzzjuoXr06zMzM0KlTJ5w5c0YSw927d9GzZ08YGhqiTp062LZt20u/h4sXL6Jnz54wNjaGjY0Nhg0bhvv377/0GKKyYGJAaoyNjWFsbIywsLAXvj5UqVRi2bJliIuLQ2hoKA4ePIipU6cCANq2bYv4+HgAwPbt23H37l20bdsW169fR48ePeDl5YXz589jy5YtOHbsGPz8/Crt3ujNoquri+HDhyMkJATPLreydetWFBQUvPDn81UOHTqE69ev49ChQwgNDUVISIha8uHn54fIyEhs3rwZ58+fx/vvv48ePXrg6tWrYp/Hjx9j/vz5+OWXXxAXFwdra2s8evQIPj4+OHbsGE6ePIn69eujV69eePTokdr1Z8yYAS8vL5w7dw7e3t4YPHgwLl++XGys6enpePvtt+Hm5obTp09j7969SE5OxqBBgzS6d6ISEYies23bNsHCwkIwMDAQ2rZtKwQEBAjnzp17Yf+tW7cKVlZW4ucHDx4IAIRDhw6Jbb6+vsLo0aPVjjt69KigVCqFJ0+elPs9UNVw+fJlyc9Shw4dhA8//FBYs2aNYGZmptZ/x44dwrP/WwsMDBSaNWsmfvbx8REcHR2F/Px8se39998XPvjgA0EQBOHmzZuCjo6OcPv2bbXzdu3aVQgICBAEQRDWrFkjABBiY2NfGntBQYFgYmIi7Nq1S2wDIHz66adq/dzd3YUxY8YIgiAICQkJAgDh7NmzgiAIwty5c4Vu3bqp9b9165YAQIiPj3/p9Yk0xYoBSXh5eeHOnTvYuXMnevTogcOHD6NFixbi36r+/vtvdO3aFTVr1oSJiQmGDRuG1NRUPH78+IXnPHfuHEJCQsSKhLGxMbp3747CwkIkJCRU0p3Rm8bZ2Rlt27bF6tWrAQDXrl3D0aNH4evrq/E5GzVqBB0dHfGznZ0dUlJSAAAXLlxAQUEBGjRooPazeuTIEVy/fl08Rl9fXzK+ITk5GaNGjUL9+vVhZmYGU1NTZGZmIjExUa3f8y/M8fDweGHF4Ny5czh06JBaLM7OzgCgFg9ReeLgQyqWgYEB3nnnHbzzzjuYMWMGPv74YwQGBqJz58549913MWbMGHzzzTewtLTEsWPH4Ovri9zcXFSrVq3Y82VmZuKTTz7BuHHjJPscHBwq+nboDebr64vPP/8cK1aswJo1a1C3bl106tQJiYmJao8YAKiNFXgRPT09tc8KhQKFhYUAnv6c6ujoICYmRi15AJ4+ZitiaGgoGcvg4+OD1NRULF26FI6OjlCpVPDw8EBubm6p7vdZmZmZ6NOnD+bPny/ZZ2dnp/F5iV6GiQGViKurK8LCwhATE4PCwkIsXLhQHIX922+/vfL4Fi1a4NKlS6hXr15Fh0pVzKBBgzB+/Hhs3LgRa9euxZgxY6BQKFCjRg08evQIWVlZMDIyAoAyz/93c3NDQUEBUlJS0KFDh1Ide/z4cfzwww/o1asXAODWrVvFDhI8efIkhg8frvbZzc2t2HO2aNEC27dvR+3ataGry/9dU+XgowRSk5qairfffhvr16/H+fPnkZCQgK1btyI4OBj9+vVDvXr1kJeXh+XLl+PGjRtYt24dVq1a9crzTps2DSdOnICfnx9iY2Nx9epV/PHHHxx8SK9kbGyMDz74AAEBAbh79y5GjBgBAHB3d0e1atXw5Zdf4vr169i4caNkBkNpNWjQAN7e3hg+fDh+//13JCQkIDo6GkFBQfjzzz9femz9+vWxbt06XL58GVFRUfD29oahoaGk39atW7F69WpcuXIFgYGBiI6OfuGfg7FjxyItLQ1DhgzBqVOncP36dezbtw8jR45EQUFBme6V6EWYGJAaY2NjuLu7Y/HixejYsSMaN26MGTNmYNSoUfj+++/RrFkzLFq0CPPnz0fjxo2xYcMGBAUFvfK8TZs2xZEjR3DlyhV06NABbm5umDlzJtc5oBLx9fXFgwcP1NbGsLS0xPr167Fnzx40adIEmzZtwqxZs8p8rTVr1mD48OGYNGkSGjZsiP79++PUqVOvfOT166+/4sGDB2jRogWGDRuGcePGwdraWtJv9uzZ2Lx5M5o2bYq1a9di06ZNcHV1Lfac9vb2OH78OAoKCtCtWzc0adIEEyZMgLm5OddNoArD1y4TERGRiCknERERiZgYEBERkYiJAREREYmYGBAREZGIiQERERGJmBgQERGRiIkBERERiZgYEBERkYiJAdEbYMSIEejfv7/4uXPnzpgwYUKlx3H48GEoFAqkp6dX+rWJqHIwMSAqgxEjRkChUEChUEBfXx/16tXDnDlzkJ+fX6HX/f333zF37twS9eUvcyIqDb6ui6iMevTogTVr1iAnJwd79uzB2LFjoaenh4CAALV+ubm50NfXL5drWlpalst5iIiex4oBURmpVCrY2trC0dERY8aMgaenJ3bu3CmW/7/55hvY29ujYcOGAJ6+jnfQoEEwNzeHpaUl+vXrh3///Vc8X0FBAfz9/WFubg4rKytMnToVz7/S5PlHCTk5OZg2bRpq1aoFlUqFevXq4ddff8W///6LLl26AAAsLCygUCjEtxMWFhYiKCgITk5OMDQ0RLNmzbBt2za16+zZswcNGjSAoaEhunTpohYnEVVNTAyIypmhoSFyc3MBAAcOHEB8fDzCw8Oxe/du5OXloXv37jAxMcHRo0dx/PhxGBsbo0ePHuIxCxcuREhICFavXo1jx44hLS0NO3bseOk1hw8fjk2bNmHZsmW4fPkyfvzxRxgbG6NWrVrYvn07ACA+Ph53797F0qVLAQBBQUFYu3YtVq1ahbi4OEycOBEffvghjhw5AuBpAjNgwAD06dMHsbGx+Pjjj/HFF19U1NdGRK8LgYg05uPjI/Tr108QBEEoLCwUwsPDBZVKJUyePFnw8fERbGxshJycHLH/unXrhIYNGwqFhYViW05OjmBoaCjs27dPEARBsLOzE4KDg8X9eXl5wltvvSVeRxAEoVOnTsL48eMFQRCE+Ph4AYAQHh5ebIyHDh0SAAgPHjwQ27Kzs4Vq1aoJJ06cUOvr6+srDBkyRBAEQQgICBBcXV3V9k+bNk1yLiKqWjjGgKiMdu/eDWNjY+Tl5aGwsBBDhw7FrFmzMHbsWDRp0kRtXMG5c+dw7do1mJiYqJ0jOzsb169fx8OHD3H37l24u7uL+3R1ddGqVSvJ44QisbGx0NHRQadOnUoc87Vr1/D48WO88847au25ublwc3MDAFy+fFktDgDw8PAo8TWI6M3ExICojLp06YKVK1dCX18f9vb20NX9/3+sjIyM1PpmZmaiZcuW2LBhg+Q8NWrU0Oj6hoaGpT4mMzMTAPDnn3+iZs2aavtUKpVGcRBR1cDEgKiMjIyMUK9evRL1bdGiBbZs2QJra2uYmpoW28fOzg5RUVHo2LEjACA/Px8xMTFo0aJFsf2bNGmCwsJCHDlyBJ6enpL9RRWLgoICsc3V1RUqlQqJiYkvrDS4uLhg586dam0nT5589U0S0RuNgw+JKpG3tzeqV6+Ofv364ejRo0hISMDhw4cxbtw4/PfffwCA8ePH49tvv0VYWBj++ecffPbZZy9dg6B27drw8fHBRx99hLCwMPGcv/32GwDA0dERCoUCu3fvxr1795CZmQkTExNMnjwZEydORGhoKK5fv44zZ85g+fLlCA0NBQB8+umnuHr1KqZMmYL4+Hhs3LgRISEhFf0VEZHMmBgQVaJq1aohIiICDg4OGDBgAFxcXODr64vs7GyxgjBp0iQMGzYMPj4+8PDwgImJCd57772XnnflypUYOHAgPvvsMzg7O2PUqFHIysoCANSsWROzZ8/GF198ARsbG/j5+QEA5s6dixkzZiAoKAguLi7o0aMH/vzzTzg5OQEAHBwcsH37doSFhaFZs2ZYtWoV5s2bV4HfDhG9DhTCi0Y0ERERkdZhxYCIiIhETAyIiIhIxMSAiIiIREwMiIiISMTEgIiIiERMDIiIiEjExICIiIhETAyIiIhIxMSAiIiIREwMiIiISMTEgIiIiET/D/KogZMCZksTAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "class balancing using weighted loss"
      ],
      "metadata": {
        "id": "rNYXIaW6TXEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Count class samples\n",
        "labels = [data.y.item() for data in train_graphs] # Use train_graphs instead of train_dataset\n",
        "class_counts = np.bincount(labels)\n",
        "total = sum(class_counts)\n",
        "\n",
        "# Compute weights: inverse frequency\n",
        "class_weights = torch.tensor([total / c for c in class_counts], dtype=torch.float32)\n",
        "print(\"Class weights:\", class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "chrFdzd-SUsq",
        "outputId": "8d8d2d0b-e553-42b0-f9b7-ee75028cc0c9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: tensor([1.8433, 2.1858])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# Move to GPU if needed\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "# Define weighted loss function\n",
        "criterion = CrossEntropyLoss(weight=class_weights)\n"
      ],
      "metadata": {
        "id": "SKsah_f7TA8G"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "import torch.nn as nn\n",
        "import torch_geometric # Import torch_geometric\n",
        "\n",
        "# Use the calculated new_vocab_size\n",
        "class GCNModel(nn.Module):\n",
        "    def __init__(self, vocab_size=new_vocab_size, embed_dim=64, hidden_dim=64, num_classes=2):\n",
        "        super(GCNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)  # token ID to vector\n",
        "        self.conv1 = GCNConv(embed_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x.squeeze(1).long(), data.edge_index  # flatten to 1D\n",
        "        batch = data.batch # Explicitly get the batch tensor\n",
        "\n",
        "        x = self.embedding(x)  # [num_nodes, embed_dim]\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Global mean pooling\n",
        "        x = torch_geometric.nn.global_mean_pool(x, batch) # Pass the explicit batch tensor\n",
        "        out = self.fc(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "vIMZSkbVTNj7"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCNModel().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += (pred == data.y).sum().item()\n",
        "            total += data.num_graphs\n",
        "\n",
        "    val_acc = correct / total\n",
        "    print(f\"Epoch {epoch:02d} | Loss: {total_loss:.4f} | Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "vphdVIikUE21",
        "outputId": "f70623fe-8d62-45b9-b869-ca74f681ac0c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-42-1559707228.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-41-2233674631.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [num_nodes, embed_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0m\u001b[1;32m    242\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         edge_index, edge_weight = add_remaining_self_loops(\n\u001b[0m\u001b[1;32m    100\u001b[0m             edge_index, edge_weight, fill_value, num_nodes)\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/loop.py\u001b[0m in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mis_undirected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_undirected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdgeIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a sample graph from your dataset\n",
        "sample_data = graph_list[0] # Use graph_list instead of dataset\n",
        "\n",
        "# Print the shape of node features\n",
        "print(\"Shape of data.x:\", sample_data.x.shape)\n",
        "\n",
        "# Preview some actual values\n",
        "print(\"Sample node features (first few rows):\")\n",
        "print(sample_data.x[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZPwTmmIOTP6Z",
        "outputId": "b202a15c-dc52-4ed9-a559-51fb10876fc2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data.x: torch.Size([256, 1])\n",
            "Sample node features (first few rows):\n",
            "tensor([[    0],\n",
            "        [42653],\n",
            "        [ 6402],\n",
            "        [ 1215],\n",
            "        [33912]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f462c51c",
        "outputId": "f7b8b057-e4b5-4b76-cb51-acf34bf66d0f"
      },
      "source": [
        "import ast\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "max_token_id = 0\n",
        "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        input_ids = ast.literal_eval(row['input_ids'])\n",
        "        if input_ids: # Check if input_ids is not empty\n",
        "             current_max = max(input_ids)\n",
        "             if current_max > max_token_id:\n",
        "                max_token_id = current_max\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row {index}: {e}\")\n",
        "\n",
        "print(f\"Maximum token ID found in the dataset: {max_token_id}\")\n",
        "\n",
        "# Set vocab_size to be max_token_id + 1\n",
        "new_vocab_size = max_token_id + 1\n",
        "print(f\"Recommended vocabulary size: {new_vocab_size}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27318/27318 [00:13<00:00, 1998.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum token ID found in the dataset: 50246\n",
            "Recommended vocabulary size: 50247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [data.y.item() for data in train_graphs] # Use train_graphs instead of train_dataset\n",
        "print(\"Label set:\", set(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uCA6K687VvTO",
        "outputId": "7b43bb63-7920-4d20-d4c2-e5483544e944"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label set: {0, 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "model = GCNModel().to(device)\n",
        "\n",
        "# Try one batch manually\n",
        "sample = train_graphs[0].to(device)\n",
        "output = model(sample)\n",
        "\n",
        "print(\"Output shape:\", output.shape)\n",
        "print(\"Output tensor:\", output)\n",
        "print(\"Label:\", sample.y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "haxS54zoV5Pq",
        "outputId": "c22fc762-e2ef-45af-c907-afb2cfc51095"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 2])\n",
            "Output tensor: tensor([[-0.0913,  0.2654]], grad_fn=<AddmmBackward0>)\n",
            "Label: tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCNModel().to(device)\n",
        "\n",
        "# Redefine loss and optimizer\n",
        "# Use class_weights calculated in cell chrFdzd-SUsq\n",
        "weights = torch.tensor([class_weights[0], class_weights[1]], dtype=torch.float).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 11):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        try:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = criterion(out, data.y.long())  # Force labels to long\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping a batch due to error: {e}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in val_loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "        total += data.num_graphs\n",
        "\n",
        "    val_acc = correct / total\n",
        "    print(f\"Epoch {epoch:02d} | Loss: {total_loss:.4f} | Val Acc: {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "mbM71JC6Wa31",
        "outputId": "929c93ab-19c4-4715-8a57-d7c28261af09"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-65-3529555184.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Redefine loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Use class_weights calculated in cell chrFdzd-SUsq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1149\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the maximum token ID in the graph_list\n",
        "max_token_id = max([int(x.x.max()) for x in graph_list])\n",
        "print(\"Max token ID in dataset:\", max_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5W4zkv7tW1sD",
        "outputId": "14f8aae7-0648-430d-f70e-e4b22aba276a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max token ID in dataset: 50246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNModel(torch.nn.Module):\n",
        "    def __init__(self, vocab_size=50247, embedding_dim=64, hidden_channels=64, num_classes=2):\n",
        "        super(GCNModel, self).__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv1 = GCNConv(embedding_dim, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x.squeeze(1), data.edge_index\n",
        "        x = self.embedding(x)\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return global_mean_pool(x, data.batch)\n"
      ],
      "metadata": {
        "id": "OYS3Fy5xXPit"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCNModel().to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "Drem9GtfXse_",
        "outputId": "a6cfe4ec-c243-438d-96f6-6019b23586cf"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-69-2074818914.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1149\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCNModel()\n",
        "\n",
        "try:\n",
        "    model.embedding = model.embedding.to(device)\n",
        "    print(\"Embedding moved to GPU successfully\")\n",
        "except Exception as e:\n",
        "    print(\"Failed at embedding:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a3ofs9GjXvSo",
        "outputId": "90d20265-700d-4243-ead1-73a655c27fa7"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed at embedding: CUDA error: device-side assert triggered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKEN_ID = 50246  # adjust based on actual model vocab size\n",
        "\n",
        "for data in graph_list: # Use graph_list instead of dataset\n",
        "    data.x = torch.clamp(data.x, min=0, max=MAX_TOKEN_ID)"
      ],
      "metadata": {
        "id": "ZPuNDiPhX_53"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = graph_list[0]\n",
        "print(\"Clamped sample token max:\", sample.x.max())\n",
        "print(\"Clamped sample token min:\", sample.x.min())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7nLoqm1nYKWP",
        "outputId": "c1939ce6-9df6-47b2-ff99-7c8d89cde54b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clamped sample token max: tensor(50140)\n",
            "Clamped sample token min: tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCNModel(vocab_size=50247).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "suMFPllrYTU1",
        "outputId": "4d79c4ce-b2cb-4bd0-a1f3-299bacfe62b1"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-74-564293215.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50247\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1149\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = torch.cat([data.y for data in graph_list])\n",
        "print(\"Unique labels:\", labels.unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qK_wUWzOYYoQ",
        "outputId": "9963aa40-6ccb-40ad-bea7-edb61c484dba"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels: tensor([0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCNModel(vocab_size=50247).to(\"cpu\")\n"
      ],
      "metadata": {
        "id": "jqBdkQVnYoXL"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCNModel(vocab_size=50247).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "4EW67mXrYxLT",
        "outputId": "38c92de5-eae3-4cdb-d5c2-5a78ad6a89de"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-78-2801224753.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50247\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1149\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "model = GCNModel(vocab_size=50247).to(device)\n"
      ],
      "metadata": {
        "id": "gUIZCzdjY5bl"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explicitly define the device for this cell\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Redefine loss and optimizer\n",
        "# Use class_weights calculated in cell chrFdzd-SUsq\n",
        "\n",
        "print(f\"Current device for weights: {device}\") # Print the device\n",
        "\n",
        "weights = torch.tensor([class_weights[0], class_weights[1]], dtype=torch.float).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Move model to device\n",
        "model = GCNModel().to(device)\n",
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, 11):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Debugging: Check labels in each batch\n",
        "        # print(f\"Epoch {epoch}, Batch {i}: data.y unique values: {torch.unique(data.y)}\")\n",
        "        # print(f\"Epoch {epoch}, Batch {i}: data.y max value: {torch.max(data.y)}\")\n",
        "        # print(f\"Epoch {epoch}, Batch {i}: data.y shape: {data.y.shape}\")\n",
        "\n",
        "\n",
        "        out = model(data)\n",
        "        # Use the weighted loss function 'criterion'\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    val_acc = evaluate(val_loader)\n",
        "    print(f\"Epoch {epoch:02d} | Loss: {total_loss:.4f} | Val Acc: {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "oL5zxXE1ZEU6",
        "outputId": "4d4427ed-2940-4207-ae3f-38ca9975c87b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device for weights: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-84-1909345458.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Current device for weights: {device}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Print the device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        preds = out.argmax(dim=1).detach().cpu().numpy()\n",
        "        labels = data.y.detach().cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "# Metrics report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(all_labels, all_preds, digits=4))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "etb3IjzXZLJY",
        "outputId": "a8b34d2b-15ed-4d8f-def2-23465e6f00ca"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-85-4293669677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mones\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         return self.apply(\n\u001b[0m\u001b[1;32m    363\u001b[0m             lambda x: x.to(device=device, non_blocking=non_blocking), *args)\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \"\"\"\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[1;32m    362\u001b[0m         return self.apply(\n\u001b[0;32m--> 363\u001b[0;31m             lambda x: x.to(device=device, non_blocking=non_blocking), *args)\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-O3JWQI4ZtoS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}